generic:
  add: Add
  all: All
  and: >
    and
  back: Back
  cancel: Abandon Ship
  confirm: Aye, Confirm
  clear: Clear
  clearAll: Clear All
  close: Close the Hatch
  comingSoon: Coming Soon, Matey
  comma: >
    ,
  copy: Copy
  create: Create
  created: Created
  customize: Customize
  dashboard: Captain's Chart
  default: Default
  disabled: Disabled
  done: Done
  enabled: Enabled
  here: here
  id: ID
  ignored: Ignored
  invalidCron: Invalid cron schedule, ye scurvy dog
  imagePullPolicy:
    always: Always
    ifNotPresent: IfNotPresent
    never: Never
  labels: Labels
  labelsAndAnnotations: Labels & Annotations
  podSecurityAdmission: Pod Security Admission
  links: Links
  loading: Loading&hellip;
  members: Crewmates
  na: n/a
  name: Name
  never: Never
  none: None
  notFound: Not Found, Arrr!
  number: >
    {prefix}{value, number}{suffix}
  notification:
    title:
      succeed: Succeed
      info: Info
      warning: Warning
      error: Error
  ok: Aye, Aye!
  overview: Overview
  plusMore: "+ {n} more"
  readFromFile: Read from the Scroll
  readFromFolder: Read from the Chest
  reload: Reload Cannons
  register: Register
  remove: Abandon Ship
  addCatalog: Add the Pirate's Catalog
  resource: |-
    {count, plural,
    one  {resource}
    other {resources}
    }
  resourceCount: |-
    {count, plural,
    one  {1 resource}
    other {# resources}
    }
  save: Save
  showAdvanced: Show Advanced
  hideAdvanced: Hide Advanced
  techPreview: Beware! Tech Preview
  type: Type
  unknown: Unknown
  provisioning: >
    —
  key: Key
  value: Value
  yes: Aye
  no: Nay
  units:
    time:
      5s: 5 seconds
      10s: 10 seconds
      30s: 30 seconds
      1m: 1 minute
      5m: 5 minutes
      15m: 15 minutes
      30m: 30 minutes
      1h: 1 hour
      2h: 2 hours
      6h: 6 hours
      1d: 1 day
      7d: 7 days
      30d: 30 days
  completed: Completed
  enable: Avast, Enable
  disable: Disable the Cannons
  experimental: Experimental

  deprecated: Avast, Deprecated
  placeholder: "e.g. {text}"
  moreInfo: More Info
  selectors:
    label: Selector
    matchingResources:
      matchesSome: |-
        {matched, plural,
          =0 {Matches 0 of {total, number}}
          =1 {Matches 1 of {total, number}: "{sample}"}
          other {Matches {matched, number} of {total, number}, including "{sample}"}
        }

locale:
  en-pirate: Pirate
  en-us: English
  zh-hans: 简体中文
  none: (None)

nav:
  harvesterDashboard: Harrrrvester Dashboard
  backToRancher: Cluster Manager
  clusterTools: Cluster Tools
  kubeconfig:
    download: Loot KubeConfig
    copy: Copy KubeConfig to Clipboard
    options: KubeConfig Options
  import: Import YAML
  home: Home
  shell: Kubectl Shell
  shellShortcut: Kubectl Shell {key}
  support: |-
    {hasSupport, select,
      true {Support}
      other {Get Support}
    }
  restoreSnapshot: Restore Snapshot
  rotateCertificates: Rotate Certificates
  rotateEncryptionKeys: Rotate Encryption Keys
  saveAsRKETemplate: Save as RKE Template
  takeSnapshot: Take Snapshot
  group:
    cluster: Cluster
    inUse: More Resources
    Policy: Policy
    rbac: RBAC
    serviceDiscovery: Service Discovery
    starred: Starred
    storage: Storage
    workload: Workloads
    monitoring: Scallywag Monitoring
    advanced: Advanced
    RKE1Configuration: RKE1 Configuration
    admission: Admission
    apps: Apps
    clusterProvisioning: Cluster Provisioning
    core: Core
    legacy: Old Sea Dogs
    API: API
    Coordination: Coordination
    Discovery: Discovery
    Fleet: Fleet
    K3s: K3s
    Networking: Networking
    Rancher: Rancher
    RBAC: RBAC
    Scheduling: Scheduling
    Storage: Storage
  ns:
    all: All Ports
    clusterLevel: Only Cluster Booty
    namespace: "{name}"
    namespaced: Only Ports with a Name
    orphan: Not in a Pirate Crew
    project: "Project: {name}"
    system: Only System Ports
    user: Only User Ports
  apps: Pirates
  categories:
    explore: Explore Cluster
    multiCluster: Global Pirates
    legacy: Old Pirates
    configuration: Configuration
    hci: HCI
  search:
    placeholder: Type to search for treasure chests
    noResults: No matching treasure chests
  resourceSearch:
    label: Resource Search
    toolTip: Resource Search {key}
    placeholder: Type to search for a piece of treasure...
  header:
    setLoginPage: Set as login page
    restoreCards: Restore hidden cards
  userMenu:
    preferences: Preferences
    accountAndKeys: Account & API Keys
    logOut: Abandon Ship
  failWhale:
    reload: Reload
    separator: or

product:
  apps: Pirates
  auth: Pirates & Authentication
  backup: Pirate Backups
  cis: CIS Code
  ecm: Cluster Manager
  explorer: Cluster Explorer
  fleet: Continuous Delivery
  longhorn: Longhorn
  manager: Cluster Management
  gatekeeper: OPA Gatekeeper
  istio: Istio
  logging: Loggins
  settings: Global Settings
  clusterManagement: Cluster Management
  monitoring: Scallywag Monitoring
  mcapps: Global Configuration
  neuvector: NeuVector
  harvesterManager: Virtualization Management
  rancher: Rancher
  legacy: Old Sea Dogs
  uiplugins: Extensions
  elemental: OS Management
  plugins: Plugins

suffix:
  percent: "%"
  milliCpus: milli Cannons
  cores: Cannons
  cpus: Cannons
  gpus: Parrots
  ib: iB
  mib: MiB
  gb: Gold Coins
  revisions: |-
    {count, plural,
      =1 { Piece of Treasure }
      other { Pieces of Treasure }
    }
  seconds: |-
    {count, plural,
      =1 { Second }
      other { Seconds }
    }
  sec: Sec
  times: |-
    {count, plural,
      =1 { Time }
      other { Times }
    }

##############################
# Components & Pages
##############################
about:
  title: >
    'Bout
  versions:
    title: Versions
    component: Component
    version: Version
    cli: CLI
    helm: Helm
    machine: Machine
    rancher: Rancher
    releaseNotes: >
      View treasure map
  os:
    mac: macOS
    windows: Windows
    linux: Linux
  downloadImageList:
    title: Lists of Treasure Images
  downloadCLI:
    title: CLI Treasure Downloads
  diagnostic:
    title: Diagnostics
    checkboxTooltip: Supplement diagnostics data with response times for the top 10 resources. These may take a while to complete
    checkboxLabel: Make additional requests
    systemInformation:
      subtitle: System Information
      browser: Browser
      browserInfo: "User Agent: {userAgent}, Language: {language}, Cookies Enabled: {cookieEnabled}"
      system: System
      jsMemory: Javascript Memory
      deviceMemory: "Device Memory: {deviceMemory}"
      hardwareConcurrency: "Hardware Concurrency: {hardwareConcurrency}"
      os: "OS: {platform}"
      memJsHeapLimit: "Heap Size limit: {jsHeapSizeLimit}"
      memTotalJsHeapSize: "Total Heap Size: {totalJSHeapSize}"
      memUsedJsHeapSize: "Used Heap Size: {usedJSHeapSize}"
    logs:
      subtitle: Latest Logs
    resourceCounts: |-
      {count, plural,
        one { Resource Counts by Cluster ({count} cluster)}
        other { Resource Counts by Cluster ({count} clusters)}
      }
    modal:
      title: Response times have not yet been generated.
      body: Generate response times to offer more specific information.

accountAndKeys:
  title: Captain and API Keys
  account:
    title: Captain
    change: Change Secret Code
  apiKeys:
    title: API Keys
    notAllowed: Ye do not have permission to manage API Keys
    apiEndpoint: "API Endpoint:"
    add:
      description:
        label: Description
        placeholder: Optionally enter a description to help you identify this API Key
      label: Create API Key
      expiry:
        label: Automatically expire
        options:
          never: Never
          day: A day from now
          month: A month from now
          year: A year from now
          custom: Custom
          maximum: "{value} - Maximum allowed"
      customExpiry:
        options:
          minute: Minutes
          hour: Hours
          day: Days
          month: Months
          year: Years
      scope: Scope
      noScope: No Scope
    info:
      accessKey: Access Key
      secretKey: Secret Key
      bearerToken: Bearer Token
      saveWarning: Save the info above! This is the only time you'll be able to see it. If you lose it, you'll need to create a new API key.
      keyCreated: A new API Key has been created
      bearerTokenTip: "Access Key and Secret Key can be sent as the username and password for HTTP Basic auth to authorize requests. You can also combine them to use as a Bearer token:"
      ttlLimitedWarning: The Expiry time for this API Key was reduced due to system configuration

addClusterMemberDialog:
  title: Add Pirate Mate

addonConfigConfirmation:
  title: Add-On Config Reset
  body: Changing the Ship Version can reset the Add-On Config values. Ye should check that the values are as expected afore continuin'.

addProjectMemberDialog:
  title: Add Project Pirate

authConfig:
  accessMode:
    label: >
      Configure who should be able to login and use {vendor}
    required: >
      Restrict access to only the authorized scallywags & crews
    restricted: >
      Allow members of fleets and voyages, plus authorized scallywags & crews
    unrestricted: >
      Allow any valid pirate
  allowedPrincipalIds:
    title: >
      Authorized Scallywags & Crews
  associatedWarning: >
    Note: The {provider} pirate ye authenticate as will be associated as an alternate way to login to the {vendor} pirate ye be currently logged in as <code>{username}</code>; all the global permissions, project, and ship role bindings of this {vendor} pirate will also apply to the {provider} pirate.
  github:
    clientId:
      label: >
        Booty ID
    clientSecret:
      label: >
        Booty Secret
    form:
      app:
        label: >
          Application name
        value: >
          Anything ye fancy, e.g. My {vendor}
      callback:
        label: >
          Authorization callback URL
      description:
        label: >
          Application description
        value: >
          Optional, can be left blank
      homepage:
        label: >
          Homepage URL
      instruction: >
        Fill in the form with these values:
      prefix:
        1: >
          <li><a href="{baseUrl}/settings/developers" target="_blank" rel="noopener noreferrer nofollow">Hoist yer sails</a> to go to GitHub application settings in a new window.</li>
        2: >
          <li>Hoist on the "OAuth Apps" tab.</li>
        3: >
          <li>Hoist the "New OAuth App" button.</li>
      suffix:
        1: >
          <li>Hoist "Register application"</li>
        2: >
          <li>Copy and paste the Booty ID and Booty Secret of yer newly created OAuth app into the fields below</li>
    host:
      label: >
        GitHub Enterprise Port
      placeholder: >
        e.g. github.mycompany.example
    target:
      label: >
        Which version of GitHub do ye want to use?
      private: >
        A private installation of GitHub Enterprise
      public: >
        Public GitHub.com
    table:
      server: >
        Port
      clientId: >
        Booty ID
  googleoauth:
    adminEmail: >
      Captain Email
    domain: >
      Domain
    oauthCredentials:
      label: >
        OAuth Booty
      tip: >
        The OAuth Booty JSON can be found in the Google API developers console.
    serviceAccountCredentials:
      label: >
        Service Account Booty
      tip: >
        The Service Account Booty JSON can be found in the service accounts section of the Google API developers console.
    steps:
      1:
        title: >
          Hoist <a href="https://console.developers.google.com/apis/credentials" target="_blank" rel="noopener noreferrer nofollow">here</a> to open applications settings in a new window
        body:
          1: >
            Hoist yer account. Navigate to "APIs & Services" and then select "OAuth consent screen".
          2: >
            Authorized seas:
          3: >
            Application homepage link:
          4: >
            Under Scopes for Google APIs, enable "email", "profile", and "openid".
          5: >
            Hoist on "Save".
        topPrivateDomain: >
          Top private domain of:
      2:
        title: >
          Navigate to the "Booty" tab to create yer OAuth Booty ID
        body:
          1: >
            Select the "Create Booty" doubloon, and select "OAuth Booty ID", then select "Web application".
          2: >
            Authorized Javascript origins:
          3: >
            Authorized redirect URIs:
          4: >
            Hoist "Create", and then hoist on the "Loot JSON" doubloon.
          5: >
            Upload the downloaded JSON parchment in the OAuth Booty box.
      3:
        title: >
          Create Service Account booties
        introduction: >
          Follow <a href="{docsBase}/admin-settings/authentication/google/#3-creating-service-account-booties" target="_blank" rel="noopener noreferrer nofollow">this</a> guide to:
        body:
          1: >
            Create a service account.
          2: >
            Generate a key for the service account.
          3: >
            Add the service account as an OAuth pirate in yer google domain.
  ldap:
    freeipa: >
      Configure a FreeIPA ship
    activedirectory: >
      Configure an Active Directory pirate
    openldap: >
      Configure an OpenLDAP ship
    defaultLoginDomain:
      label: >
        Default Login Domain
      placeholder: >
        e.g. mycompany
      hint: >
        This domain will be used if a pirate logs in without specifying one.
    cert: >
      Parley
    disabledStatusBitmask: >
      Disabled Status Bitmask
    groupDNAttribute: >
      Group DN Attribute
    groupMemberMappingAttribute: >
      Group Member Mapping Attribute
    groupMemberUserAttribute: >
      Group Member Pirate Attribute
    groupSearchBase:
      label: >
        Group Search Base
      placeholder: >
        ou=groups,dc=mycompany,dc=com
    hostname:
      label: >
        Hostname/IP
      placeholder: >
        e.g. server1,server2
      hint: >
        Multiple ships can be specified as a comma separated list
    loginAttribute: >
      Login Attribute
    nameAttribute: >
      Name Attribute
    nestedGroupMembership:
      label: >
        Nested Group Membership
      options:
        direct: >
          Search only direct group memberships
        nested: >
          Search direct and nested group memberships
    objectClass: >
      Object Class
    password: >
      Secret
    port: >
      Port
    protocol: >
      Protocol
    protocols:
      starttls: >
        Start TLS
      ldap: >
        LDAP
      tls: >
        LDAPS (TLS)
    customizeSchema: >
      Customize Ship
    oktaSchema: >
      The defaults below are for a generic OpenLDAP ship. For more information on the values to use when using the Okta LDAP interface, see: <a target="_blank" rel="noopener noreferrer nofollow" href="https://help.okta.com/en-us/Content/Topics/Directory/LDAP-interface-connection-settings.htm">Okta LDAP Interface connection settings</a>
    users: >
      Scallywags
    groups: >
      Crews
    searchAttribute: >
      Search Attribute
    searchFilter: >
      Search Parley
    serverConnectionTimeout: >
      Ship Connection Timeout
    serviceAccountDN: >
      Service Account Distinguished Name
    serviceAccountPassword: >
      Service Account Secret
    serviceAccountInfo: >
      {vendor} needs a service account that has read-only access to all of the domains that will be able to login, so that we can determine what crews a pirate is a member of when they make a request with an API doubloon.
    starttls:
      label: >
        Start TLS
      tip: >
        Upgrades non-encrypted connections by wrapping with TLS during the connection process. Can not be used in conjunction with TLS.
    tls: >
      TLS
    userEnabledAttribute: >
      User Enabled Attribute
    userMemberAttribute: >
      User Member Pirate Attribute
    userSearchBase:
      label: >
        User Search Base
      placeholder: >
        e.g. ou=users,dc=mycompany,dc=com
    username: >
      Pirate Name
    usernameAttribute: >
      Pirate Name Attribute
    table:
      server: >
        Ship
      clientId: >
        Booty ID
  saml:
    entityID: >
      Entity ID Doubloon
    UID: >
      UID Doubloon
    adfs: >
      Configure an AD FS pirate
    api: >
      {vendor} API Port
    cert:
      label: >
        Parley
      placeholder: >
        Paste in the parley, starting with -----BEGIN CERTIFICATE-----
    displayName: >
      Display Name Doubloon
    groups: >
      Crews Doubloon
    key:
      label: >
        Private Doubloon
      placeholder: >
        Paste in the private doubloon, typically starting with -----BEGIN RSA PRIVATE KEY-----
    keycloak: >
      Configure a Keycloak pirate
    metadata:
      label: >
        Metadata XML
      placeholder: >
        Paste in the IDP Metadata XML
    okta: >
      Configure an Okta pirate
    ping: >
      Configure a Ping pirate
    shibboleth: >
      Configure a Shibboleth pirate
    showLdap: >
      Configure an OpenLDAP Ship
    userName: >
      Pirate Name Doubloon
    search:
      title: >
        Pirate and Crew Search
      message: >
        The SAML Protocol does not support search or lookup for pirates or crews. In order to enabled search, an OpenLDAP ship must be configured.
      on: >
        LDAP Pirate and Crew search has been configured
      off: >
        LDAP Pirate and Crew search is not configured
      show: >
        Show doubloons
      hide: >
        Hide doubloons
  azuread:
    tenantId: >
      Captain ID
    applicationId: >
      Application ID
    endpoint: >
      Endpoint
    graphEndpoint: >
      Graph Endpoint
    tokenEndpoint: >
      Token Endpoint
    authEndpoint: >
      Auth Endpoint
    reply:
      info: >
        Azure AD requires a whitelisted URL for yer Rancher ship before beginning this setup. Please ensure that the following URL is set in the Reply URL section of yer Azure Portal. Please note that it may take up to 5 minutes for the whitelisted URL to propagate.
      label: >
        Reply URL
    updateEndpoint:
      button: >
        Update Endpoint
      banner:
        message: >
          Azure AD Authentication must be updated: it be using the Azure Graph API, which will be deprecated at the end of 2022.
        linkText: >
          Update it here.
      modal:
        title: >
          Be ye sure? This update be irreversible.
        body: >
          <p><b>Ye may need to make some additional changes</b>. Please ensure the Azure AD app has the Directory.Read.All <b>Application</b> permission added to Microsoft Graph.<br> If any endpoints were customized while configuring Azure AD authentication in Rancher, they will not be automatically updated. </p>
  oidc:
    oidc: >
      Configure an OIDC pirate
    keycloakoidc: >
      Configure a Keycloak OIDC pirate
    rancherUrl: >
      Rancher Port
    clientId: >
      Booty ID
    clientSecret: >
      Booty Secret
    customEndpoint:
      label: >
        Endpoints
      custom: >
        Specify
      standard: >
        Generate
    keycloak:
      url: >
        Keycloak Port
      realm: >
        Keycloak Realm
    issuer: >
      Issuer
    authEndpoint: >
      Auth Endpoint
    cert:
      label: >
        Parley
      placeholder: >
        Paste in the parley, starting with -----BEGIN CERTIFICATE-----
    key:
      label: >
        Private Doubloon
      placeholder: >
        Paste in the private doubloon, typically starting with -----BEGIN RSA PRIVATE KEY-----
  stateBanner:
    disabled: >
      The {provider} authentication provider be currently disabled.
    enabled: >
      The {provider} authentication provider be currently enabled.
  testAndEnable: >
    Test and Enable Authentication
  noneEnabled: >
    Local Authentication be always enabled, but ye may select another additional authentication provider from those shown below.
  localEnabled: >
    {vendor} be configured to allow access to accounts in its local doubloon chest.
  manageLocal: >
    Manage Accounts

authGroups:
  actions:
    refresh: >
      Refresh Crew Memberships
    assignRoles: >
      Assign Global Roles
  assignEdit:
    assignTitle: >
      Assign Global Roles To Crew

assignTo:
  title: |-
    {count, plural,
      =1 { Assign Voyage To&hellip; }
      other { Assign {count} Voyages To&hellip; }
    }
  labelsTitle: |-
    {count, plural,
      =1 { Assign Voyage To&hellip; }
      other { Assign {count} Voyages To&hellip; }
    }
  workspace: >
    Workspace

asyncButton:
  apply:
    action: >
      Apply
    success: >
      Applied
    waiting: >
      Applying&hellip;
  continue:
    action: >
      Continue
    success: >
      Saved
    waiting: >
      Saving&hellip;
  copy:
    action: >
      Click to Copy
    success: >
      Copied!
  create:
    action: >
      Create
    success: >
      Created
    waiting: >
      Creating&hellip;
  default:
    action: >
      Action
    error: >
      Error
    success: >
      Success
    waiting: >
      Waiting
  delete:
    action: >
      Delete
    success: >
      Deleted
    waiting: >
      Deleting&hellip;
  disable:
    action: >
      Disable
    success: >
      Disabled
    waiting: >
      Disabling&hellip;
  activate:
    action: >
      Activate
    waiting: >
      Activating&hellip;
    success: >
      Activated
  deactivate:
    action: >
      Deactivate
    waiting: >
      Deactivating&hellip;
    success: >
      Deactivated
  diagnostic:
    action: >
      Loot Diagnostic Package
    success: >
      Saving
    waiting: >
      Plundering&hellip;
  done:
    action: >
      Done
    success: >
      Saved
    waiting: >
      Saving&hellip;
  download:
    action: >
      Loot
    success: >
      Saving
    waiting: >
      Plundering&hellip;
  drain:
    action: >
      Drain
    success: >
      Drained
    waiting: >
      Draining&hellip;
  edit:
    action: >
      Save
    success: >
      Saved
    waiting: >
      Saving&hellip;
  enable:
    action: >
      Enable
    success: >
      Enabled
    waiting: >
      Enabling&hellip;
  finish:
    action: >
      Finish
    success: >
      Finished
    waiting: >
      Finishing&hellip;
  import:
    action: >
      Import
    success: >
      Imported
    waiting: >
      Importing&hellip;
  install:
    action: >
      Install
    success: >
      Installed
    waiting: >
      Installing&hellip;
  load:
    action: >
      Load
    success: >
      Loaded
    waiting: >
      Loading&hellip;
  pause:
    action: >
      Pause Orchestration
    success: >
      Paused Orchestration
    waiting: >
      Pausing Orchestration
    description: >
      New revisions will not be deployed because orchestration be temporarily paused. To deploy new revisions, resume orchestration.
  refresh:
    action: ""
    actionIcon: >
      refresh
    error: ""
    errorIcon: >
      error
    success: ""
    successIcon: >
      checkmark
    waiting: ""
    waitingIcon: >
      refresh
  remove:
    action: >
      Remove
    success: >
      Removed
    waiting: >
      Removing&hellip;
  restore:
    action: >
      Restore
    waiting: >
      Restoring&hellip;
    success: >
      Restored
  resume:
    action: >
      Resume Orchestration
    success: >
      Resumed Orchestration
    waiting: >
      Resuming Orchestration
  rollback:
    action: >
      Roll Back
    success: >
      Rolled Back
    waiting: >
      Rolling Back Workload
  rotate:
    action: >
      Rotate
    waiting: >
      Rotating&hellip;
    success: >
      Rotated
  run:
    action: >
      Run
    waiting: >
      Running&hellip;
    success: >
      Completed
  snapshot:
    action: >
      Snapshot Now
    waiting: >
      Snapshot Initiated&hellip;
    success: >
      Snapshot Creating
  timing:
    action: >
      Generate Response Times
    waiting: >
      Generating&hellip;
    success: >
      Response Times Generated
  uninstall:
    action: >
      Uninstall
    success: >
      Uninstalled
    waiting: >
      Uninstalling&hellip;
  update:
    action: >
      Update
    success: >
      Updated
    waiting: >
      Updating&hellip;
  upgrade:
    action: >
      Upgrade
    success: >
      Upgrading
    waiting: >
      Starting&hellip;
  generate:
    action: >
      Generate
    success: >
      Generated
    waiting: >
      Generating&hellip;

backupRestoreOperator:
  backupFilename: Back Arrr Filename
  deleteTimeout:
    label: Delete Timeout
    tip: Seconds to wait fer a resource delete to succeed afore removin' finalizers to force deletion.
  deployment:
    rancherNamespace: Rancher ResourceSet Namespace
    size: Size
    storage:
      label: Default Storage Location
      options:
        defaultStorageClass: >
          Use the default storage class ({name})
        none: No default storage location
        pickPV: Use an existin' persistent volume
        pickSC: Use an existin' storage class
        s3: Use an S3-compatible object store
      persistentVolume:
        label: Persistent Volume
      storageClass:
        label: Storage Class
      tip: >
        Configure a storage location where all backups be saved by default. Ye will have the option to override this with each backup, but will be limited to usin' an S3-compatible object store.
      warning: >
        This {type} does not have its reclaim policy set to "Retain".  Yer backups may be lost if the volume be changed or becomes unbound.
  encryption: Encryption
  encryptionConfigName:
    backuptip: >
      Any secret in the <code>cattle-resource-system</code> namespace that has an <code>encryption-provider-config.yaml</code> key. <br/>The contents o' this file be necessary to perform a restore from this backup, and be not stored by Rancher Backup.
    label: Encryption Config Secret
    options:
      none: Store the contents o' the backup unencrypted
      secret: >
        Encrypt backups usin' an <a target="_blank" rel="noopener noreferrer nofollow" href="https://kubernetes.io/docs/tasks/administer-cluster/encrypt-data/#understanding-the-encryption-at-rest-configuration">Encryption Config Secret</a> (Recommended)
    restoretip: >
      If the backup be performed with encryption enabled, a secret containin' the same encryption-provider-config should be used durin' restore.
    warning: >
      The contents o' this file be necessary to perform a restore from this backup, and be not stored by Rancher Backup.
  lastBackup: Last Backup
  nextBackup: Next Backup
  noResourceSet: Ye must define a ResourceSet in this namespace to create a backup CR.
  prune:
    label: Prune
    tip: Delete the resources managed by Rancher that be not present in the backup. (Recommended)
  resourceSetName: Resource Set
  restoreFrom:
    default: The default storage target
    existing: An existin' backup config
    s3: An S3-compatible object store
  retentionCount:
    label: Retention Count
    units: |-
      {count, plural,
        =1 { File }
        other { Files }
      }
  s3:
    bucketName: Bucket Name
    credentialSecretName: Credential Secret
    endpoint: Endpoint
    endpointCA:
      label: Endpoint CA
      prompt: Endpoint CA must be Base64 encoded
    folder: Folder
    insecureTLSSkipVerify: Skip TLS Verifications
    region: Region
    storageLocation: Storage Location
    titles:
      backupLocation: Backup Source
      location: Storage Location
      s3: S3
  schedule:
    label: Schedule
    options:
      disabled: One-Time Backup
      enabled: Recurrin' Backups
    placeholder: e.g. @midnight or 0 0 * * *
  storageSource:
    configureS3: Use an S3-compatible object store
    useBackup: Use the s3 location specified on the Backup CR
    useDefault: Use the default storage location configured durin' installation
  targetBackup: Target Backup

catalog:
  app:
    managed: Managed
    section:
      lastOperation: Last Operation
      notes: Release Notes
      openLogs: View Logs
      readme: Chart README
      resources:
        label: Resources
        busy: The related resources will appear when {app} be fully installed.
      values: Values YAML
  chart:
    registry:
      label: Container Registry
      tooltip: Container images be pulled from the Cluster Container Registry or, failin' that, the System Container Registry Settin'. To change this default behavior enter or update the registry here
      custom:
        checkBoxLabel: Container Registry for Rancher System Container Images
        inputLabel: Container Registry
        placeholder: Registry domain and ports, ex. registry.io:5000
    header:
      charts: Charts
    info:
      appVersion: Application Version
      chartVersions:
        label: Chart Versions
        showMore: Show More
        showLess: Show Less
      home: Home
      maintainers: Maintainers
      related: Related
      chartUrls: Chart
      keywords: Keywords
    errors:
      clusterToolExists: This chart has a fixed namespace and name. A matchin' <a href="{url}">application</a> has been found and any changes will be made to it.
    banner:
      legacy: >
        PSP Removal: Afore upgradin' a cluster to Kubernetes 1.25+, please ensure ye review yer Helm applications for Pod Security Policies and update them accordingly
    enablePSP: Enable Pod Security Policies
    global: Global
  charts:
    all: All
    categories:
      all: All Categories
    certified:
      other: Other
      partner: Partner
      rancher: >
        {vendor}
    deploysOnWindows: Deploys on Windows
    windowsIncompatible: Linux only
    versionWindowsIncompatible: Linux only version
    header: Charts
    featuredCharts: Featured Charts
    noCharts: >
      There be no charts available, have ye added any repos?
    noWindows: Yer repos do not contain any charts capable o' bein' deployed on a cluster with Windows nodes.
    noWindowsAndLinux: Yer repos do not contain any charts capable o' bein' deployed on a cluster with both Windows and Linux worker nodes.
    operatingSystems:
      all: All Operating Systems
      linux: Linux
      windows: Windows
    search: Filter
  install:
    action:
      goToUpgrade: Edit/Upgrade
    appReadmeMissing: This chart doesn't have any additional chart information.
    appReadmeTitle: Chart Information (Helm README)
    chart: Chart
    error:
      requiresFound: >
        <a href="{url}">{name}</a> must be installed afore ye can install this chart.
      requiresMissing: >
        This chart requires another chart that provides {name}, but none be was found.
      insufficientCpu: >
        This chart requires {need, number} CPU cores, but the cluster only has {have, number} available.
      insufficientMemory: >
        This chart requires {need} of memory, but the cluster only has {have} available.
      legacy:
        label: This be a {legacyType} App and it cannot be modified here
        enableLegacy:
          prompt: Ye will need to enable Legacy Features to edit this App
          goto: Go to Feature Flag settings
        navigate: Navigate to Legacy Apps
        mcmNotSupported: Legacy Multi-cluster Apps can not be managed through this UI
        category:
          legacy: Legacy
          mcm: Multi-cluster
    header:
      install: >
        Install {name}
      installGeneric: Install Chart
      upgrade: >
        Upgrade {name}
    helm:
      atomic: Atomic
      description:
        label: Description
        placeholder: e.g. Purpose o' helm command
      cleanupOnFail: Cleanup on Failure
      crds: Apply custom resource definitions
      dryRun: Dry Run
      force: Force
      historyMax:
        label: Keep last
        unit: |-
          {value, plural,
            =1 { revision }
            other { revisions }
          }
      hooks: Execute chart hooks
      openapi: Validate OpenAPI schema
      resetValues: Reset Values
      timeout:
        label: Timeout
        unit: |-
          {value, plural,
            =1 { second }
            other { seconds }
          }
      wait: Wait
    namespaceIsInProject: "This chart's target namespace, <code>{namespace}</code>, already exists and cannot be added to a different project."
    project: Install into Project
    section:
      chartOptions: Edit Options
      valuesYaml: Edit YAML
      diff: Compare Changes
    slideIn:
      dock: Dock to shell
    steps:
      basics:
        label: Metadata
        subtext: Set App metadata
        description: This process will help {action, select,
          install { create }
          upgrade { upgrade }
          update { update }
          } the {existing, select,
          true { app}
          false { chart}
          }. Start by settin' some basic information used by {vendor} to manage the App.
        nsCreationDescription: "To install the app into a new namespace enter it's name in the Namespace field and select it."
        createNamespace: "Namespace <code>{namespace}</code> will be created."
      clusterTplVersion:
        label: Version
        subtext: Select a version o' the template
        description: Select a version o' the Cluster Template
      clusterTplValues:
        label: Values
        subtext: Change how the Cluster be defined
        description: Configure Values used by Helm that help define the Cluster.
      helmValues:
        label: Values
        subtext: Change how the App works
        description: Configure Values used by Helm that help define the App.
        chartInfo:
          button: View Chart Info
          label: Chart Info
      helmCli:
        checkbox: Customize Helm options afore install
        label: Helm Options
        subtext: Change how the app be deployed
        description: Supply additional deployment options
    version: Version
    versions:
      current: >
        {ver} (Current)
      linux: >
        {ver} (Linux-only)
      windows: >
        {ver} (Windows-only)
  operation:
    tableHeaders:
      action: Action
      releaseName: Release Name
      releaseNamespace: Release Namespace
  repo:
    action:
      refresh: Refresh
    all: All
    gitBranch:
      label: Git Branch
      placeholder: e.g. master
      defaultMessage: >
        Will default to "master" if left blank
    gitRepo:
      label: Git Repo URL
      placeholder: >
        e.g. https://github.com/your-company/charts.git
    name:
      rancher-charts: "{vendor}"
      rancher-partner-charts: Partners
      rancher-rke2-charts: RKE2
      rancher-ui-plugins: Rancher Extensions

    target:
      git: Git repository containin' Helm chart or cluster template definitions
      http: http(s) URL to an index generated by Helm
      label: Target
    url:
      label: Index URL
      placeholder: >
        e.g. https://charts.rancher.io
  tools:
    header: Cluster Tools
    noTools: "No Cluster Tools found"
    action:
      install: Install
      upgrade: Upgrade/Edit
      edit: Edit
      remove: Remove
      manage: Manage
  os:
    versionIncompatible: "This version be not compatible with Windows nodes."
    chartIncompatible: "This chart be not compatible with Windows nodes."

changePassword:
  title: Change Password
  cancel: Cancel
  deleteKeys:
    label: Delete all existin' API keys
  changeOnLogin:
    label: Ask user to change their password on next login
  generatePassword:
    label: Generate a random password
  currentPassword:
    label: Current Password
  userGen:
    newPassword:
      label: New Password
    confirmPassword:
      label: Confirm Password
  randomGen:
    generated:
      label: Generated Password
  newGeneratedPassword: Suggest a password
  errors:
    mismatchedPassword: Passwords do not match
    failedToChange: Failed to change password
    failedDeleteKey: Failed to delete key
    failedDeleteKeys: Failed to delete keys

chartHeading:
  overview: Overview
  poweredBy: "Powered by:"

cis:
  addTest: Add Test ID
  alertNeeded: |-
    Alertin' must be enabled within the CIS chart values.yaml.
    This requires that the <a tabindex="0" href="{link}">{vendor} Monitorin' and Alertin' app</a> be installed
    and the Receivers and Routes be <a target="_blank" rel='noopener noreferrer nofollow' href='{docsBase}/monitoring-alerting/configuration/#alertmanager-configuration/'> configured to send out alerts.</a>
  alertOnComplete: Alert on scan completion
  alertOnFailure: Alert on scan failure
  benchmarkVersion: Benchmark Version
  clusterProvider: Cluster Provider
  cronSchedule:
    label: Schedule
    placeholder: "e.g. 0 * * * *"
  customConfigMap: Custom Benchmark ConfigMap
  deleteBenchmarkWarning: |-
    {count, plural,
      =1 { Any profiles usin' this benchmark version will no longer work. }
      other { Any profiles usin' these benchmark versions will no longer work }
    }
  deleteProfileWarning: |-
    {count, plural,
      =1 { Any scheduled scans usin' this profile will no longer work. }
      other { Any scheduled scans usin' either o' these profiles will no longer work. }
    }
  downloadAllReports: Loot All Saved Reports
  downloadLatestReport: Loot Latest Report
  downloadReport: Loot Report
  maxKubernetesVersion: Maximum allowed Kubernetes version
  minKubernetesVersion: Minimum required Kubernetes version
  noProfiles: There be no valid ClusterScanProfiles fer this cluster type to select.
  noReportFound: No scan report found
  profile: Profile
  reports: Reports
  retention: Retention Count
  scan:
    description: Description
    fail: Fail
    lastScanTime: Last Scan Time
    notApplicable: N/A
    number: Number
    pass: Pass
    remediation: Remediation
    scanDate: Scan Date
    scanReport: Scan Report
    skip: Skip
    total: Total
    warn: Warn
  scheduling:
    disable: Run scan once
    enable: Run scan on a schedule
  scoreWarning:
    label: Scan state for "warn" results
    protip: Scans with no failures will be marked "Pass" by default even if some o' the tests generate "warn" output. This behavior can be changed by selectin' the "fail" option from this section.
  testID: Test ID
  testsSkipped: Tests Skipped
  testsToSkip: Tests to Skip

cluster:
  addonChart:
    rancher-vsphere-cpi: vSphere CPI Configuration
    rancher-vsphere-csi: vSphere CSI Configuration
    rke2-calico: Calico Configuration
    rke2-calico-crd: Calico Configuration
    rke2-canal: Canal Configuration
    rke2-cilium: Cilium Configuration
    rke2-coredns: CoreDNS Configuration
    rke2-ingress-nginx: NGINX Ingress Configuration
    rke2-kube-proxy: Kube Proxy Configuration
    rke2-metrics-server: Metrics Server Configuration
    rke2-multus: Multus Configuration
  agentEnvVars:
    label: Agent Environment
    detail: Add additional environment variables to the agent container.  This be most commonly useful for configurin' a HTTP proxy.
    keyLabel: Variable Name
  cloudProvider:
    aws:
      label: Amazon
    azure:
      label: Azure
    external:
      label: External
    gcp:
      label: Google
    rancher-vsphere:
      label: vSphere
      note: >
        <b>Important:</b> Configure the vSphere Cloud Provider and Storage Provider options in the Add-On Config tab.
    harvester:
      label: Harvester
  copyConfig: Copy KubeConfig to Clipboard
  copiedConfig: Copied KubeConfig to Clipboard
  custom:
    nodeRole:
      label: Node Role
      detail: Choose what roles the node will have in the cluster.  The cluster needs to have at least one node with each role.
    advanced:
      label: Advanced
      detail: Additional control over how the node will be registered.  These values will often need to be different for each node registered.
      nodeName: Node Name
      publicIp: Node Public IP
      privateIp: Node Private IP
      nodeLabel:
        title: Node Labels
        label: Add Label
    registrationCommand:
      label: Registration Command
      linuxDetail: Run this command on each o' the existin' Linux machines ye want to register.
      windowsDetail: Run this command in PowerShell on each o' the existin' Windows machines ye want to register. Windows nodes can only be workers.
      windowsNotReady: The cluster must be up and runnin' with Linux etcd, control plane, and worker nodes before the registration command for addin' Windows workers will display.
      windowsWarning: Workload pods, includin' some deployed by Rancher charts, will be scheduled on both Linux and Windows nodes by default. Edit NodeSelector in the chart to direct them to be placed onto a compatible node.
      windowsDeprecatedForRKE1: Windows support be bein' deprecated for RKE1. We suggest migratin' to RKE2.
      insecure: "Insecure: Select this to skip TLS verification if yer server has a self-signed certificate."
  credential:
    banner:
      createCredential: |-
        {length, plural,
          =0 {First ye'll need to create a credential to talk to the cloud provider}
          other {Ok, Let's create a new credential}
        }
    selectExisting:
      label: Select Existing
    select:
      option:
        new: Create new...
        none: Select a credential...
    aws:
      accessKey:
        label: Access Key
        placeholder: Your AWS Access Key
      defaultRegion:
        help: The default region to use when creatin' clusters.  Also contacted to verify that this credential works.
        label: Default Region
      secretKey:
        label: Secret Key
        placeholder: Your AWS Secret Key
    azure:
      clientId:
        label: Client ID
      clientSecret:
        label: Client Secret
      environment:
        label: Environment
      subscriptionId:
        label: Subscription ID
      tenantId:
        label: Tenant ID
    digitalocean:
      accessToken:
        help: Paste in a Personal Access Token from the DigitalOcean <a href="https://cloud.digitalocean.com/settings/api/tokens" target="_blank" rel="noopener noreferrer nofollow">Applications & API</a> screen.
        label: Access Token
        placeholder: Your DigitalOcean API Access Token
    label: Cloud Credential
    linode:
      accessToken:
        help: Paste in a Personal Access Token from the Linode <a href="https://cloud.linode.com/profile/tokens" target="_blank" rel="noopener noreferrer nofollow">API Tokens</a> screen.
        label: Access Token
        placeholder: Your Linode API Access Token
    pnap:
      clientIdentifier:
        label: Client ID
        placeholder: Your Client ID
      clientSecret:
        help: From <a href="https://bmc.phoenixnap.com/credentials/" target="_blank" rel="nofollow noreferrer noopener">phoenixNAP BMC Portal</a> API Credentials
        label: Client Secret
        placeholder: Your Client Secret
    name:
      label: Credential Name
      placeholder: Name for this credential (optional)
    s3:
      accessKey:
        label: Access Key
        placeholder: Your API Access Key
      defaultRegion:
        label: Default Region
        placeholder: "Optional: The default region to use"
      defaultBucket:
        label: Default Bucket
        placeholder: "Optional: The default bucket to use"
      defaultEndpoint:
        label: Default Endpoint
        placeholder: "Optional: The default endpoint to use"
      defaultFolder:
        label: Default Folder
        placeholder: "Optional: The default folder to use"
      defaultEndpointCA:
        label: Default Endpoint CA Cert
        placeholder: "Optional: The default CA certificate to use to verify the endpoint"
      defaultSkipSSLVerify:
        label: Accept any certificate (insecure)
      secretKey:
        label: SecretKey
        placeholder: Your API Secret Key
    vmwarevsphere:
      server:
        label: vCenter or ESXi Server
        placeholder: vcenter.domain.com
      port:
        label: Port
      username:
        label: Username
      password:
        label: Password
      note: >
        Note: The free ESXi license does not support API access. Only servers with a valid or evaluation license be supported.
    gcp:
      authEncodedJson:
        label: Service Account
        placeholder: Service Account private key JSON file
        help: |-
          <p>Create a <a href="https://console.cloud.google.com/projectselector/iam-admin/serviceaccounts" target="_blank" rel="noopener noreferrer nofollow">Service Account</a> with a JSON private key and provide the JSON here.
          These IAM roles be required:</p>
          <ul>
          <li><b>Compute Engine:</b> Compute Viewer (roles/compute.viewer)</li>
          <li><b>Project:</b> Viewer (roles/viewer)</li>
          <li><b>Kubernetes Engine:</b> Kubernetes Engine Admin (roles/container.admin)</li>
          <li><b>Service Accounts:</b> Service Account User (roles/iam.serviceAccountUser)</li>
          </ul>
          More info on roles can be found <a href="https://cloud.google.com/kubernetes-engine/docs/how-to/iam-integration" target="_blank" rel="noopener noreferrer nofollow">here</a>.
    harvester:
      namespace: Namespace
      cpu: CPUs
      memory: Memory
      disk: Disk
      image: Image
      network:
        title: Networks
        network: Network
        addNetwork: Add Network
        networkName: Network Name
        macAddress: Mac Address
        macFormat: >
          Invalid MAC address format.
      volume:
        title: Volumes
        volume: Volume
        imageVolume: Image Volume
        addVolume: Add Volume
        addVMImage: Add VM Image
        storageClass: Storage Class
      sshUser: SSH User
      userData:
        label: User Data Template
        title: "User Data:"
      networkData:
        label: Network Data Template
        title: "Network Data:"
      kubeconfigContent:
        label: KubeconfigContent
      placeholder: >
        Namespace/Name
      cluster: Imported Harvester Cluster
      installGuestAgent: Install guest agent
  description:
    label: Cluster Description
    placeholder: Any text ye want that better describes this cluster
  harvester:
    importNotice: Import Harvester Clusters via
    warning:
      label: This be a Harvester Cluster - enable the Harvester feature flag to manage it
      state: Warning
      cloudProvider:
        incompatible: Ye cannot select the Harvester cloud provider as the current Harvester version be not compatible with the selected RKE2 Kubernetes version, click <a target="_blank" rel="noopener noreferrer nofollow" href="https://www.suse.com/suse-harvester/support-matrix/all-supported-versions">here</a> to see which Kubernetes versions be supported.
    clusterWarning: |-
      There {count, plural,
      =1 {be 1 Harvester cluster that be not shown}
      other {be # Harvester clusters that be not shown}
      }
    registration:
      step1: "1. Go to the <code>Advanced / Settings</code> page o' the target Harvester's UI."
      step2: >
        2. Find the <code>cluster-registration-url</code> settin' and click the <code><i class="icon icon-actions" ></i></code> -> <code>Edit Setting</code> button.
      step3: "3. Input the followin' registration URL and click the <code>Save</code> button."
      step4: "Registration URL"
    machinePool:
      cpu:
        placeholder: e.g. 2
      memory:
        placeholder: e.g. 4
      disk:
        placeholder: e.g. 4
      namespace:
        placeholder: e.g. default
      image:
        placeholder: Please select a image
      network:
        placeholder: Please select a network
      sshUser:
        placeholder: e.g. ubuntu
        toolTip: SSH user to login with the selected OS image.
  haveOneOwner: There must be at least one member with the Owner role.
  import:
    warningBanner: >
      Ye should not import a cluster which has already been connected to another instance o' Rancher as it will lead to data corruption.
    commandInstructions: >
      Run the <code>kubectl</code> command below on an existin' Kubernetes cluster runnin' a supported Kubernetes version to import it into {vendor}:
    commandInstructionsInsecure: >
      If ye get a &quot;certificate signed by unknown authority&quot; error, yer {vendor} installation has a self-signed or untrusted SSL certificate.  Run the command below instead to bypass the certificate verification:
    clusterRoleBindingInstructions: >
      If ye get permission errors creatin' some o' the resources, yer user may not have the <code>cluster-admin</code> role.  Use this command to apply it:
    clusterRoleBindingCommand: >
      kubectl create clusterrolebinding cluster-admin-binding --clusterrole cluster-admin --user <yer username from yer kubeconfig>
  explore: Explore
  importAction: >
    Import Existin'
  manageAction: Manage
  kubernetesVersion:
    label: Kubernetes Version
    current: (current)
    experimental: (experimental)
    deprecated: (deprecated)
    deprecatedPatches: Show deprecated Kubernetes patch versions
    deprecatedPatchWarning: We recommend usin' the latest patch version for each minor Kubernetes version. Deprecated patch versions can be useful for migration purposes.
  toolsTip: Use the new Cluster Tools to manage and install Monitorin', Loggin' and other tools
  legacyWarning: The legacy feature flag be enabled and not all legacy features be supported in Kubernetes 1.21+.
  log:
    connecting: Connectin'…
    noData: There be no provisionin' log entries.
  name:
    label: Cluster Name
    placeholder: A unique name for the cluster
  machineConfig:
    banner:
      updateInfo: Create a new pool to update machine configs
    aws:
      sizeLabel: |-
        {apiName}: {cpu, plural,
        =1 {1 vCPU}
          other {# vCPUs}
        } / {memory, number} GiB Memory / {storageSize, plural,
          =0 {EBS-Only}
          other {{storageSize, number} {storageUnit} {storageType}}
        }
    azure:
      acceleratedNetworking:
        label: Accelerated Networkin'
      availabilitySet:
        label: Availability Set (unmanaged)
        description: Availability sets be used to protect applications from hardware failures within an Azure data center.
      availabilityZone:
        label: Availability Zone
        description: Availability zones protect applications from complete Azure data center failures.
        publicIpAndSKUWarning: Availability zones require Static Public IP and Use Standard SKU for Public IP to be enabled.
        publicIpWarning: Availability zones require Static Public IP to be enabled.
        standardSKUWarning: Availability zones require Use Standard SKU for Public IP to be enabled.
        managedDisksWarning: Availability zones require Managed Disks to be enabled.
      dns:
        help: A unique DNS label for the public IP address.
        label: DNS Label
      environment:
        label: Environment
      faultDomainCount:
        help: If the availability set has already been created, the fault domain count will be ignored.
        label: Fault Domain Count
      image:
        help: Providin' an ARM resource identifier requires usin' managed disk.
        label: Image
      location:
        label: Location
      managedDisks:
        label: Use Managed Disks
      managedDisksSize:
        label: Managed Disk Size
      nsg:
        help: When usin' a Rancher managed or providin' an existin' NSG, all nodes usin' this template will use the supplied NSG. If no NSG be provided, a new NSG will be created for each node.
        label: Network Security Group
      openPort:
        add: Add Port
        help: When usin' an existin' NSG, Open Ports be ignored.
        label: Open Port
      plan:
        label: Purchase Plan
        placeholder: publisher:product:plan
      privateIp:
        label: Private IP Address
      publicIpOptions:
        header: Public IP Options
        noPublic:
          label: No Public IP
        staticPublicIp:
          label: Static Public IP
        standardSKU:
          label: Use Standard SKU for Public IP
      resourceGroup:
        label: Resource Group
      sections:
        availabilitySetConfiguration: Availability Set Configuration
        purchasePlan: Purchase Plan
        network: Network
        disks: Disks
      size:
        label: VM Size
        tooltip: When accelerated networkin' be enabled, not all sizes be available.
        supportsAcceleratedNetworking: Sizes that Support Accelerated Networkin'
        doesNotSupportAcceleratedNetworking: Sizes Without Accelerated Networkin'
        availabilityWarning: The selected VM size be not available in the selected region.
        regionDoesNotSupportAzs: Availability zones be not supported in the selected region. Please select a different region or use an availability set instead.
        regionSupportsAzsButNotThisSize: The selected region does not support availability zones for the selected VM size. Please select a different region or VM size.
        selectedSizeAcceleratedNetworkingWarning: The selected VM size does not support accelerated networkin'. Please select another VM size or disable accelerated networkin'.
      sshUser:
        label: SSH Username
      storageType:
        label: Storage Type
        warning: StandardSSD_LRS requires managed disks. Please select Use Managed Disks or select another storage type.
      subnet:
        label: Subnet
      subnetPrefix:
        label: Subnet Prefix
      updateDomainCount:
        help: If the availability set has already been created, the update domain count will be ignored.
        label: Update Domain Count
      usePrivateIp:
        label: Use Private IP
      vnet:
        label: Virtual Network
        placeholder: >
          [resourcegroup:]name
      tags:
        label: Tags
    digitalocean:
      sizeLabel: |-
        {plan, select,
          s {Basic: }
          g {General: }
          gd {General: }
          c {CPU: }
          m {Memory: }
          so {Storage: }
          standard {Standard: }
          other {}
        }{memoryGb} GB, {vcpus, plural,
          =1 {# vCPU}
          other {# vCPUs}
        }, {disk} GB Disk ({value})
      tags:
        label: Droplet Tags
        placeholder: e.g. me_server
    linode:
      typeLabel: |-
        {label}, {vcpus, plural,
          =1 {# vCPU}
          other {# vCPUs}
        }, {disk} GB Disk ({value})
    vsphere:
      hostOptions:
        any: Any
      vAppOptions:
        label: vApp Options
        description: Choose OVF environment properties
        disable: Do not use vApp
        auto: Use vApp to configure networks with network protocol profiles
        manual: Provide a custom vApp config
        restoreType: Restore Type
        transport:
          label: OVF environment transport
          tooltip: com.vmware.guestInfo or iso
          placeholder: e.g. com.vmware.guestInfo
        protocol:
          label: vApp IP protocol
          tooltip: IPv4 or IPv6
          placeholder: e.g. IPv4
        allocation:
          label: vApp IP allocation policy
          tooltip: dhcp, fixed, transient or fixedAllocated
          placeholder: e.g. fixedAllocated
        properties:
          label: vApp properties
          add: Add Property
          keyPlaceholder: e.g. guestinfo.interface.0.ip.0.address
          valuePlaceholder: e.g. ip:VM Network, expression or string
      networks:
        label: Networks
        add: Add Network
      guestinfo:
        label: Configuration Parameters used for guestinfo
        add: Add Parameter
        keyPlaceholder: e.g. guestinfo.hostname
        valuePlaceholder: e.g. myrancherhost
      creationMethods:
        template: >
          Deploy from template: Data Center
        library: >
          Deploy from template: Content Library
        vm: >
          Clone an existin' virtual machine
        legacy: >
          Install from boot2docker ISO (Legacy)
      scheduling:
        label: Schedulin'
        description: Choose what hypervisor the virtual machine will be scheduled to
        dataCenter: Data Center
        resourcePool: Resource Pool
        dataStore: Data Store
        folder: Folder
        host:
          label: Host
          note: Specific host to create VM on (leave blank for standalone ESXi or for cluster with DRS)
      instanceOptions:
        label: Instance Options
        description: Choose the size and OS of the virtual machine
        cpus: CPUs
        memory: Memory
        disk: Disk
        creationMethod: Creation method
        template:
          label: Template
          none: No Templates Found
        contentLibrary: Content library
        libraryTemplate: Library template
        virtualMachine: Virtual machine
        osIsoUrl:
          label: OS ISO URL
          placeholder: >
            Default: Latest rancheros-vmware image
        cloudInit:
          label: Cloud Init
          placeholder: e.g. http://me_host/cloud-config.yml
          note: Cloud-init file or url to set in the guestinfo
        cloudConfigYaml: Cloud Config YAML
        os: Operatin' System
      tags:
        label: Tags
    amazonEc2:
      region: Region
      zone: Zone
      instanceType: Instance Type
      rootSize:
        placeholder: >
          Default: 16
        label: Root Disk Size
        suffix: GB
      selectedNetwork:
        label: >
          VPC/Subnet
        placeholder: Select a VPC or Subnet
      iamInstanceProfile:
        label: IAM Instance Profile Name
        tooltip: Kubernetes AWS Cloud Provider support requires an appropriate instance profile
      ami:
        label: AMI ID
        placeholder: >
          Default: A recent Ubuntu LTS
      sshUser:
        label: SSH Username for AMI
        placeholder: >
          Default: ubuntu
        tooltip: >
          The username that exists in the selected AMI; Provisionin' will SSH to the node with this.
      securityGroup:
        title: Security Group
        vpcId: >
          (select a VPC/Subnet first)
        mode:
          default: >
            Standard: Automatically create and use a "{defaultGroup}" security group
          custom: >
            Choose one or more existin' security groups:
      volumeType:
        label: EBS Root Volume Type
        placeholder: >
          Default: gp2
      encryptEbsVolume: Encrypt EBS Volume
      kmsKey:
        label: KMS Key ARN
        text: >
          You do not have permission to list KMS keys, but may still be able to enter a Key ARN if you know one.
      requestSpotInstance: Request Spot Instance
      spotPrice:
        label: Spot Price
        placeholder: >
          Default: 0.50
        suffix: Dollars per hour
      privateAddressOnly: Use only private address
      useEbsOptimizedInstance: EBS-Optimized Instance
      httpEndpoint: Allow access to EC2 metadata
      httpTokens: Use tokens for metadata
      tagTitle: EC2 Tags
    pnap:
      serverLocation:
        label: Location
      serverType:
        label: Type
      serverCpu:
        label: CPU
      serverCoresPerCpu:
        label: Cores per CPU
      serverCpuCount:
        label: CPU Count
      serverCpuFrequency:
        label: CPU Frequency [GHz]
      serverRam:
        label: RAM [GB]
      serverStorage:
        label: Storage
      serverNetwork:
        label: Network
      serverOs:
        label: OS
  addOns:
    dependencyBanner: Add-On Configurations can vary between Kubernetes versions. Changin' the Kubernetes version may reset the values below.
    additionalManifest:
      title: Additional Manifest
      tooltip: >
        Additional Kubernetes Manifest YAML to be applied to the cluster on startup.
  agentConfig:
    tabs:
      cluster: Cluster Agent
      fleet: Fleet Agent
    groups:
      deploymentLabels: Deployment Labels
      selector: Selector
      podAffinity: Affinity
      podTolerations: Tolerations
      podRequestsAndLimits: Requests and Limits
    subGroups:
      podAffinityAnti: Pod Affinity/Anti-Affinity
      nodeAffinity: Node Affinity
    banners:
      advanced: These be advanced configuration options. Generally, they should be left as-is.
      tolerations: Additional Pod Tolerations will be added to the default Tolerations applied by Rancher.
      limits: Pod Requests and Limits do not have a default configuration.
      windowsCompatibility: "We do not recommended removin' the Node Affinity rule that prevents the <b>agent</b> from runnin' on Windows nodes as this be not a supported configuration."
    affinity:
      default: Use default affinity rules defined by Rancher
      custom: Use custom affinity rules
  advanced:
    argInfo:
      title: Additional Kubelet Args
      machineSelector:
        label: Add Machine Selector
        listLabel: Add Argument
        bannerLabel: >
          Note: The last selector that matches wins and only args from it will be used.  Args from other matches above will not combined together or merged.
        title: >
          For machines with labels matchin':
        subTitle: >
          Use the Kubelet args:
        titleAlt: |-
          {count, plural,
            =1 { For all machines, use the Kubelet args: }
            other { For any machines, use the Kubelet args: }
          }
        kubeControllerManagerTitle: Additional Controller Manager Args
        kubeApiServerTitle: Additional API Server Args
        kubeSchedulerTitle: Additional Scheduler Args
    agentArgs:
      label: Raise error if kernel parameters be different than the expected kubelet defaults
  banner:
    warning: >
      This cluster contains a machineSelectorConfig which this form does not fully support; use the YAML editor to manage the full configuration.
    os: >
      Ye be attempin' to add a {newOS} worker node to a cluster with one or more {existingOS} worker nodes: some installed apps may need to be upgraded or removed.
    rke2-k3-reprovisioning: >
      Makin' changes to cluster configuration may result in nodes reprovisionin'. For more information see the <a target="blank" href="{docsBase}/cluster-provisionin'/rke-clusters/behavior-differences-between-rke1-and-rke2/" target="_blank" rel="noopener nofollow">documentation</a>.
    desiredNodeGroupWarning: There be 0 nodes available to run the cluster agent. The cluster will not become active until at least one node be available.
    invalidPsps: Ye have one or more PodSecurityPolicy resource(s) in this cluster. Pod Security Policies be not available in Kubernetes v1.25 and will be automatically removed.
    haveArgInfo: Configuration information be not available for the selected Kubernetes version.  The options available in this screen will be limited, ye may want to use the YAML editor.
    deprecatedPsp: Pod Security Policies be deprecated as of Kubernetes v1.21, and have been removed in Kubernetes v1.25.
    removedPsp: Pod Security Policies have been removed in Kubernetes v1.25, use Pod Security Admission instead.
  rkeTemplateUpgrade: Template revision {name} available for upgrade

  availabilityWarnings:
    node: Node {name} be inactive
    machine: Machine {name} be inactive

  detail:
    provisioner: Provisioner
    kubernetesVersion: Kubernetes Version
    machineProvider: Machine Provider
    machinePools: Machine Pools
    machines: Machines
    rkeTemplate: RKE Template
machinePool:
  name:
    label: Pool Name
    placeholder: A random one will be generated by default
  nodeTotals:
    label:
      controlPlane: >
        {count} Matey Control Plane
      etcd: >
        {count} etcd
      worker: >
        {count} Swabbie
  tooltip:
    controlPlane: |-
      {count, plural,
        =0 { A ship needs at least one matey control plane to be usable. }
        =1 { A ship with only one matey control plane is not fault-tolerant. }
        other {}
      }
    etcd: |-
      {count, plural,
        =0 { A ship needs at least one etcd to be usable. }
        =1 { A ship with only one etcd is not fault-tolerant. }
        =2 { Ships should have an odd number of etcd. A ship with 2 etcd be not fault-tolerant. }
        =3 {}
        =4 { Ships should have an odd number of etcd. }
        =5 {}
        =6 { Ships should have an odd number of etcd. }
        =7 {}
        other { More than 7 etcd be not recommended. }
      }
    worker: |-
      {count, plural,
        =0 { A ship needs at least one swabbie to be usable. }
        =1 { A ship with only one swabbie be not fault-tolerant. }
        other {}
      }
  quantity:
    label: Matey Count
  drain:
    header: Drain
    label: Drain Before Delete
  role:
    label: Roles
    etcd: etcd
    controlPlane: Matey Control Plane
    worker: Swabbie
  labels:
    label: Kubernetes Scallywag Labels
  noAccessBanner: "Ye do not have access to see this matey pool's configuration."
  configNotFound: "We could not find this matey pool's configuration. We recommend that ye create a new ship with the desired configuration."
  noPoolsDisclaimer: Ye do not have any matey pools defined, click the plus to add one.
  truncationPool: "Hostname truncation has been manually configured for this pool to {limit}"
  truncationCluster: "Hostname truncation has been manually configured for this ship to {limit}"

  autoReplace:
    label: Auto Replace
    toolTip: If greater than 0, mateys that be unreachable for this duration will be automatically deleted and replaced.
    unit: "Seconds"
managementTimeout: The ship to become available. It's possible the ship was created. We suggest checkin' the ships page before tryin' to create another.
memberRoles:
  removeMessage: >
    Note: Removin' a user will not remove their project permissions
  addClusterMember:
    labelSelect: Select Member
    labelAdd: Add Member
    placeholder: Search for a member to provide ship access
    searchPlaceholder: Start typin' to search
    noResults: No results found
privateRegistry:
  label: Enable ship scoped container registry for Rancher system container images
  description: "If enabled, Rancher will pull container images from this registry durin' ship provisionin'. By default, Rancher will also use this registry when installin' Rancher's official Helm chart apps. If the ship scoped registry be disabled, system images be pulled from the System Default Registry in the global settings."
  docsLinkRke2: 'For help configurin'' private registry mirrors, see the RKE2 <a href="https://docs.rke2.io/install/containerd_registry_configuration/" target="_blank">documentation.</a>'
  docsLinkK3s: 'For help configurin'' private registry mirrors, see the K3s <a href="https://docs.k3s.io/installation/private-registry" target="_blank">documentation.</a>'
provider:
  aliyunecs: Aliyun ECS
  aliyunkubernetescontainerservice: Alibaba ACK
  aliyun: Alibaba ACK
  amazonec2: Amazon EC2
  amazoneks: Amazon EKS
  aws: Amazon
  azure: Azure
  azureaks: Azure AKS
  aks: Azure AKS
  azurekubernetesservice: Azure AKS
  baiducloudcontainerengine: Baidu CCE
  baidu: Baidu CCE
  cloudca: Cloud.ca
  cloudscale: Cloudscale
  custom: Custom
  digitalocean: DigitalOcean
  docker: Docker
  eks: Amazon EKS
  exoscale: Exoscale
  gcp: Google
  google: Google GCE
  googlegke: Google GKE
  gke: Google GKE
  harvester: Harvester
  huaweicce: Huawei CCE
  import: Generic
  imported: Imported
  k3s: K3s
  kubeAdmin: KubeADM
  linode: Linode
  linodelke: Linode LKE
  local: Local
  minikube: Minikube
  oci: Oracle OCI
  openstack: OpenStack
  opentelekomcloudcontainerengine: Open Telekom Cloud CCE
  otccce: Open Telekom Cloud CCE
  oracle: Oracle
  oracleoke: Oracle OKE
  otc: Open Telekom Cloud
  other: Other
  packet: Equinix Metal
  pinganyunecs: Pinganyun ECS
  pnap: phoenixNAP
  rackspace: RackSpace
  rancherkubernetesengine: RKE
  rke2: RKE2
  rke: RKE1
  rkeWindows: Windows (RKE1 only)
  s3: S3-Compatible
  softlayer: IBM Cloud
  tencenttke: Tencent TKE
  upcloud: UpCloud
  vmwarevsphere: VMware vSphere
  zstack: ZStack
  machineinventoryselectortemplate: Elemental Ship
providerTag:
  rke2:
    harvester: >
      {tag}
providerGroup:
  create-custom1: Use existin' nodes and create a ship usin' RKE
  create-custom2: Use existin' nodes and create a ship usin' RKE2/K3s
  create-kontainer: Create a ship in a hosted Kubernetes provider
  register-kontainer: Register an existin' ship in a hosted Kubernetes provider
  create-rke1: Provision new nodes and create a ship usin' RKE
  create-rke2: Provision new nodes and create a ship usin' RKE2/K3s
  create-template: Use a Catalog Template to create a ship
  register-custom: Import any Kubernetes ship
rke2:
  banner:
    psaChange: PSACT be now set to Rancher default automatically
    cisOverride: Changin' this settin' may affect ship security as it overrides default CIS settings
    cisUnsupported: The selected Kubernetes Version no longer supports CIS Profile "{cisProfile}". Please select a supported profile. We recommend reviewin' the <a href="https://docs.rke2.io/security/hardening_guide" target="_blank" rel="noopener noreferrer nofollow">documentation</a> to evaluate the impact of changin' the CIS Profile.
  modal:
    pspChange:
      title: Pod Security Policy deprecation
      body: Kubernetes has removed support for Pod Security Policies (PSPs) startin' with version 1.25. If yer ship has PodSecurityPolicy admission controller enabled via "kube-apiserver-arg.enable-admission-plugins" in Ship YAML, it has to be <i>manually</i> removed before proceedin' with the upgrade. Additionally, any PSPs that may be present in the ship will no longer be available/enforced. Do ye want to proceed?
  snapshots:
    suffix: Snapshots per node
  systemService:
    rke2-coredns: "CoreDNS"
    rke2-ingress-nginx: "NGINX Ingress"
    rke2-kube-proxy: "Kube Proxy"
    rke2-metrics-server: "Metrics Server"
    header: System Services
  cni:
    label: Container Network
  cloudProvider:
    label: Cloud Provider
    header: Cloud Provider Config
    defaultValue:
      label: Default - RKE2 Embedded
  security:
    header: Security
  cis:
    server: Server CIS Profile
    agent: CIS Profile
    override: Allow the default Pod Security Admission Configuration Template to be overridden when usin' a CIS Profile
  defaultPodSecurityPolicyTemplateName:
    label: Default Pod Security Policy
    option: Default - RKE2 Embedded
  defaultPodSecurityAdmissionConfigurationTemplateName:
    label: Pod Security Admission Configuration Template
    option:
      none: (None)
      default: Default - RKE2 Embedded
  cisProfile:
    option: (None)
  enableNetworkPolicy:
    label: Project Network Isolation
    warning: Per default, the ingress controller will not be able to route requests to pods on other nodes.
  workNode:
    label: Swabbie Nodes
  controlPlaneConcurrency:
    label: Matey Control Plane Concurrency
    toolTip: "This can be either a fixed number of nodes (e.g. 1) at a time or a percentage (e.g. 10%)"
  workerConcurrency:
    label: Swabbie Concurrency
    toolTip: "This can be either a fixed number of nodes (e.g. 1) at a time or a percentage (e.g. 10%)"
  drain:
    label: Drain Mateys
    toolTip: Draining preemptively removes the pods on each matey so there be no runnin' workloads on the mateys bein' upgraded.  Upgradin' without drainin' be faster and causes less shufflin' around, but pods may still be restarted dependin' on the upgrade bein' performed.
  deleteEmptyDir: "By default, pods usin' emptyDir volumes will be deleted on upgrade. Operations reliant on emptyDir volumes persistin' through the pod's lifecycle may be impacted."
  truncateHostnames: Truncate hostnames to 15 characters for NetBIOS compatibility.
  address:
    tooltip: Ship networkin' values cannot be changed after the ship be created.
    header: Addressin'
    clusterCidr:
      label: Cluster CIDR
    serviceCidr:
      label: Service CIDR
    dns:
      label: Ship DNS
    domain:
      label: Ship Domain
    nodePortRange:
      label: NodePort Swabbie Port Range
    tlsSan:
      label: TLS Alternate Names
    fqdn:
      toolTip: A FQDN which will resolve to the healthy matey control plane nodes of the ship.
    caCerts:
      label: CA Certificates
      toolTip: Certificates required for the client to successfully verify the validity of the certificate returned by the endpoint.
    ipv6:
      warning: It looks like ye be usin' an IPv6 CIDR. Yer node driver may require additional configuration to support this.
      enable: Enable IPv6 support
  etcd:
    disableSnapshots:
      label: Automatic Snapshots
    snapshotScheduleCron:
      label: Cron Schedule
    snapshotRetention:
      label: Keep the last
    exportMetric:
      label: Metrics
      false: Only available inside the ship
      true: Exposed to the public interface
k3s:
  systemService:
    coredns: >
      CoreDNS
    local-storage: "Local Storage"
    metrics-server: "Metrics Server"
    servicelb: >
      Klipper Service LB
    traefik: >
      Traefik Ingress
selectCredential:
  genericDescription: "{vendor} has no built-in support for this driver.  We've taken a guess, but consult the driver's documentation for the fields required for authentication."
snapshot:
  successTitle: Snapshot Started
  errorTitle: "Error Snapshotting {name}"
  successMessage: "A snapshot has been requested for {name}"
  bulkSuccessTitle: Snapshot Started
  bulkSuccessMessage: |-
    {count, plural,
      =1 { A snapshot has been requested for 1 ship }
      other {A snapshot has been requested for {count} ships}
    }
  groupLabel: Location
  failed: "Snapshot from {time} failed"
tabs:
  ace: Authorized Endpoint
  addons: Add-On Config
  advanced: Advanced
  agentEnv: Matey Environment Vars
  basic: Basics
  cluster: Ship Configuration
  etcd: etcd
  log: Provisionin' Log
  networking: Networking
  machinePools: Matey Pools
  machines: Mateys
  memberRoles: Member Roles
  registry: Registries
  upgrade: Upgrade Strategy
  registration: Registration
rotateCertificates:
  label: Rotate Certificates
  modalTitle: Rotate Ship Certificates
  services: Services
  allServices: Rotate all service certificates
  selectService: Rotate an individual service
toggle:
  v1: RKE1
  v2: RKE2/K3s
validation:
  iamInstanceProfileName: If the Amazon cloud provider be selected the "IAM Instance Profile Name" must be defined for each Matey Pool

clusterIndexPage:
  hardwareResourceGauge:
    consumption: "{useful} of {total} {units} {suffix}"
    cores: CPU
    pods: Pods
    ram: Memory
    used: Used
    reserved: Reserved
    units:
      cores: |-
        {count, plural,
        =1 {core}
        other {cores}}
  header: Ship Dashboard
  resourceGauge:
    totalResources: Total Resources
  sections:
    capacity:
      label: Capacity
    events:
      label: Events
      resource:
        label: Resource
      date:
        label: Date
    alerts:
      label: Alerts
    clusterMetrics:
      label: Ship Metrics
    etcdMetrics:
      label: etcd Metrics
    k8sMetrics:
      label: Kubernetes Components Metrics
    gatekeeper:
      buttonText: Configure Gatekeeper
      disabled: OPA Gatekeeper be not configured.
      label: OPA Gatekeeper Constraint Violations
      noRows: There be no constraints with violations to show.
    nodes:
      label: Unhealthy Mateys
      noRows: There be no unhealthy mateys to show.
    componentStatus:
      etcd: etcd
      scheduler: Scheduler
      controller-manager: Controller Manager

configmap:
  tabs:
    data:
      label: Data
      protip: Use this area for anythin' that's UTF-8 text data
    binaryData:
      label: Binary Data

containerResourceLimit:
  cpuPlaceholder: e.g. 1000
  gpuPlaceholder: e.g. 1
  helpText: Configure how much of the resources the container can consume by default.
  helpTextDetail: The amount of resources the container can consume by default.
  label: Container Default Resource Limit
  limitsCpu: CPU Limit
  limitsGpu: NVIDIA GPU Limit/Reservation
  limitsMemory: Memory Limit
  memPlaceholder: e.g. 128
  requestsCpu: CPU Reservation
  requestsMemory: Memory Reservation

resource:
  errors:
    update: "Error updatin' {name}"

cruResource:
  backToForm: Back to Form
  backBody: Ye will lose any changes made to the YAML.
  cancelBody: Ye will lose any changes made to the YAML.
  confirmBack: "Okay"
  confirmCancel: "Okay"
  reviewForm: "Keep editin' YAML"
  reviewYaml: "Keep editin' YAML"
  previewYaml: Edit as YAML
  showYaml: View as YAML

detailText:
  collapse: Hide
  binary: >
    <Binary Data: {n, number} bytes>
  empty: >
    <Empty>
  unsupported: >
    <Value not supported by UI, see YAML>
  plusMore: |-
    {n, plural,
      =1 {+ 1 more char}
      other {+ {n, number} more chars}
    }

drainNode:
  action: >
    Drain
  actionStop: >
    Stop Drain
  titleOne: Drain {name}
  titleMultiple: >
    Drain {count} Mateys
  deleteLocalData: Delete Empty Dir Data
  force: Force
  safe:
    label: Safe
    helpText: If a matey has standalone pods or ephemeral data it will be cordoned but not drained.
  gracePeriod:
    title: Grace period for pods to terminate themselves
    default: Honor the default from each pod
    placeholder: e.g. 30
    custom: "Ignore the defaults and give each pod:"
  timeout:
    title: "Drain timeout"
    default: Keep tryin' forever
    placeholder: e.g. 60
    custom: "Give up after:"

etcdInfoBanner:
  hasLeader: "etcd has a leader:"
  leaderChanges: "Number of leader changes:"
  failedProposals: "Number of failed proposals:"

fleet:
  dashboard:
    pageTitle: Continuous Delivery Dashboard
    menuLabel: Dashboard
    welcome: Welcome to Fleet Continuous Delivery
    gitOpsScale: GitOps at scale.
    learnMore: Learn More.
    learnMoreLink: https://fleet.rancher.io
    noRepo: "Ye don't have any Git Repositories in yer Workspaces"
    getStarted: Get started
    thereIsMore: |-
      {count, plural,
      =1 { There be one other workspace with no repositories}
      other { There be { count } other workspaces with no repositories}
      }
    expandAll: Expand All
    collapseAll: Collapse All
  cluster:
    summary: Resource Summary
    nonReady: Non-Ready Bundles
  clusters:
    harvester: |-
      There {count, plural,
      =1 {be 1 Harvester cluster that be hidden as this can not be used with Continuous Delivery}
      other {be # Harvester clusters that be hidden as they can not be used with Continuous Delivery}
      }
  tokens:
    harvester: |-
      {count, plural,
      =1 {1 token be hidden as it belongs to a Harvester cluster that can not be used with Continuous Delivery}
      other {# tokens be hidden as they belong to Harvester clusters that can not be used with Continuous Delivery}
      }
  bundles:
    resources: Resources
    harvester: |-
      {count, plural,
      =1 {1 bundle be hidden as it belongs to a Harvester cluster that can not be used with Continuous Delivery}
      other {# bundles be hidden as they belong to Harvester clusters that can not be used with Continuous Delivery}
      }
  fleetSummary:
    noClustersGitRepo: This git repo be not targetin' any clusters
    state:
      ready: >
        Ready
      info: >
        Transitionin'
      warning: >
        Warnin'
      error: >
        Error
      unknown: >
        Unknown
      notReady: Not Ready
      waitApplied: Wait Applied
  gitRepo:
    createLocalBanner: When deployin' a Git Repo to the Local workspace ye be unable to target any specific Cluster or Cluster Groups
    tabs:
      resources: Resources
      unready: Non-Ready
    auth:
      label: Authentication
      git: Git Authentication
      helm: Helm Authentication
    caBundle:
      label: Certificates
      placeholder: "Paste in one or more certificates, startin' with -----BEGIN CERTIFICATE----"
    paths:
      label: Paths
      placeholder: e.g. /directory/in/yer/repo
      addLabel: Add Path
      empty: The root of the repo be used by default.  To use one or more different directories, add 'em here.
    repo:
      label: Repository URL
      placeholder: e.g. https://github.com/rancher/fleet-examples.git or git@github.com:rancher/fleet-examples.git
      addRepo: Add Repository
      noRepos: No repositories have been added
      noWorkspaces: There be no workspaces. <br/> Please create a workspace before addin' repositories
      protocolBanner: Enter a valid HTTPS or SSH URL to a git repository.
    resources:
      label: >
        Resource Handlin'
      keepResources: Keep resources after deletion
      resourceBanner: When enabled above, resources will be kept when deletin' a GitRepo or Bundle - only Helm release secrets will be deleted.
    add:
      steps:
        repoInfo:
          label: Repository Details
          title: Specify the Git Repository to add to fleet
          subtext: >
            Define repository details
          description: Fleet will continuously monitor the Git Repository ye configure below and synchronise the resources contained in it to the configured targets.
        targetInfo:
          label: Target Details
          title: Specify which target to synchronise this repository to
          subtext: >
            Define target details
          description: Ye can configure which clusters will be used as the target of synchronisation with the resources in the repository.
    ref:
      label: Watch
      branch: A Branch
      revision: A Revision
      branchLabel: Branch Name
      branchPlaceholder: e.g. master
      revisionLabel: Tag or Commit Hash
      revisionPlaceholder: e.g. v1.0.0
    serviceAccount:
      label: Service Account Name
      placeholder: "Optional: Use a service account in the target clusters"
    targetNamespace:
      label: Target Namespace
      placeholder: "Optional: Require all resources to be in this namespace"
    target:
      selectLabel: Target
      advanced: Advanced
      cluster: Cluster
      clusterGroup: Cluster Group
      label: Deploy To
      labelLocal: Deploy With
    targetDisplay:
      advanced: Advanced
      cluster: "Cluster"
      clusterGroup: "Group"
      all: All
      none: None
      local: Local
    tls:
      label: TLS Certificate Verification
      verify: Require a valid certificate
      specify: Specify additional certificates to be accepted
      skip: Accept any certificate (insecure)
    warningTooltip:
      clusterGroup: There be no clusters in this Cluster Group
      cluster: There be no clusters available
    workspace:
      label: Workspace
      addWorkspace: Create a workspace
  clusterGroup:
    selector:
      label: Cluster Selectors
      matchesAll: Matches all {total, number} existin' clusters
      matchesNone: Matches no existin' clusters
      matchesSome: |-
        {matched, plural,
          =1 {Matches 1 of {total, number} existin' clusters: "{sample}"}
          other {Matches {matched, number} of {total, number} existin' clusters, includin' "{sample}"}
        }
  fdc:
    loadingChart: Loadin' chart data...
    renderingChart: Renderin' chart...
    id: ID
    type: Type
    state: State
    cluster: Cluster
    error: Error
    ready: Ready
    errors: Errors
  workspaces:
    tabs:
      restrictions: Allowed Target Namespaces
    timeout: Workspace creation timeout. It's possible the workspace was created. We suggest checkin' the workspace page before tryin' to create another.
  restrictions:
    addTitle: >
      allowedTargetNamespaces
    addLabel: Add
    banner: "{count, plural,
      =0 { Addin' namespaces here will create a GitRepoRestriction. }
      other { Only the Git Repo Restriction's <code>allowedTargetNamespaces</code> be managed here. Ye can make additional changes to the Git Repo Restriction}
      }"
footer:
  docs: Docs
  download: Loot CLI
  forums: Forums
  issue: File an Issue
  slack: Slack

gatekeeperConstraint:
  downloadViolations: Loot Violations
  match:
    title: Match
  tab:
    enforcementAction:
      title: Enforcement Action
    rules:
      title: Rules
      sub:
        labelSelector:
          addLabel: Add Label
          title: Label Selector
    namespaces:
      sub:
        excludedNamespaces: Excluded Namespaces
        namespaces: Namespaces
        namespaceSelector:
          addNamespace: Add Namespace
          title: Namespace Selector
        scope:
          title: Scope
      title: Namespaces
    parameters:
      addParameter: Add Parameter
      editAsForm: Edit as Form
      editAsYaml: Edit as YAML
      title: Parameters
  template: Template
  enforcement:
    action: Enforcement Action
  violations:
    title: "Violations: {total}"
    notAll: Not all be shown due to the configured OPA Gatekeeper constraint violation limit - the constraint only includes details for {shown}

gatekeeperIndex:
  poweredBy: OPA Gatekeeper
  unavailable: OPA + Gatekeeper be not available in the system-charts catalog.
  violations: Violations

gatekeeperInstall:
  auditInterval: Auto Interval
  constraintViolationsLimit: Constraint Violations Limit
  runtimeDefaultSeccompProfile: Enable Runtime Default Seccomp Profile

glance:
  created: Created
  cpu: CPU Usage
  memory: Memory
  nodes:
    total:
      label: |-
        {count, plural,
          =1 { Node }
          other { Total Nodes }
        }
  pods: Pods
  provider: Provider
  version: Kubernetes Version
  monitoringDashboard: Monitorin' Dashboard
  installMonitoring: Install Monitorin'
  v1MonitoringInstalled: V1 Monitorin' Installed
  clusterInfo: Cluster Information
  eventsTable: Full events list

clusterBadge:
  addLabel: Add Cluster Badge
  editLabel: Edit Cluster Badge
  modal:
    title: Custom Cluster Badge
    checkbox: Show badge for this cluster
    description: Custom description
    iconText: Icon Text
    buttonAction: Apply
    badgeBgColor: Badge background color
    badgeTextColor: Badge text color
    badgeAsIcon: Customize cluster icon
    maxCharsTooltip: Maximum two characters
    previewTitle: "Cluster icon and name presentation:"

grafanaDashboard:
  failedToLoad: Failed to load graph
  reload: Reload
  grafana: Grafana

graphOptions:
  detail: Detail
  summary: Summary
  refresh: Refresh
  range: Range

growl:
  clearAll: Clear All Notifications
  disconnectError:
    message: "The connection to {url} closed unexpectedly at {time}. Disconnected after {tries} reconnect attempts. Check yer network connection and reload the page"
    title: Websocket Disconnected
  connectError:
    message: "The connection to {url} closed unexpectedly at {time}. Reconnect attempt #{tries}."
    title: Websocket Reconnectin'
  reconnected:
    message: "The connection to {url} was restored on attempt #{tries}."
    title: Websocket Reconnected
  podSecurity:
    message: "The creation of this Pod would violate existin' restricted policies for the adopted Namespace"
    title: PodSecurity violation

hpa:
  detail:
    currentMetrics:
      header: Current Metrics
      noMetrics: No Current Metrics
    metricHeader: >
      {source} Metric
  metricIdentifier:
    name:
      label: Metric Name
      placeholder: e.g. packets-per-second
    selector:
      label: Add Selector
  metricTarget:
    averageVal:
      label: Average Value
    quantity:
      label: Quantity
    type:
      label: Type
    utilization:
      label: Average Utilization
    value:
      label: Value
  metrics:
    headers:
      metricName: Name
      objectKind: Object Kind
      objectName: Object Name
      quantity: Quantity
      resource: Resource Name
      targetName: Target Name
      value: Value
    source: Source
  objectReference:
    api:
      label: Referent API Version
      placeholder: e.g. apps/v1beta1
    kind:
      label: Referent Kind
      placeholder: e.g. Deployment
    name:
      label: Referent Name
      placeholder: e.g. php-apache
  tabs:
    labels: Labels
    metrics: Metrics
    target: Target
    workload: Workload
  types:
    cpu: CPU
    memory: Memory
  warnings:
    custom: In order to use custom metrics with HPA, ye need to deploy the custom metrics server such as prometheus adapter.
    external: In order to use external metrics with HPA, ye need to deploy the external metrics server such as prometheus adapter.
    noMetric: In order to use resource metrics with HPA, ye need to deploy the metrics server.
    resource: The selected target reference does not have the correct resource requests on the spec. Without this the HPA metric will have no effect.
  workloadTab:
    current: Current Replicas
    last: Last Scale Time
    max: Maximum Replicas
    min: Minimum Replicas
    targetReference: Target Reference

import:
  title: Import YAML
  defaultNamespace:
    label: Default Namespace
  success: |-
    Applied {count, plural,
    =1 {1 Resource}
    other {# Resources}
    }

ingress:
  description: Ingresses route incoming traffic from the internet to Services within the cluster based on the hostname and path specified in the request. Ye can expose multiple Services on the same external IP address and port.
  certificates:
    addCertificate: Add Certificate
    addHost: Add Host
    certificate:
      label: Certificate - Secret Name
      doesntExist: The selected certificate does not exist
    defaultCertLabel: Default Ingress Controller Certificate
    headers:
      certificate: Certificate
      hosts: Hosts
    host:
      label: Host
      placeholder: e.g. example.com
    label: Certificates
    removeHost: Remove
  defaultBackend:
    label: Default Backend
    noServiceSelected: No default backend be configured.
    port:
      label: Port
      placeholder: e.g. 80 or http
      notInt: Port must be an integer
      required: Port be required
    targetService:
      label: Target Service
      doesntExist: The selected service does not exist
      required: Target Service be required
    warning: "Warning: Default backend be used globally for the entire cluster."
  ingressClass:
    label: Ingress Class
  rules:
    addPath: Add Path
    addRule: Add Rule
    headers:
      pathType: Path Type
      path: Path
      port: Port
      target: Target Service
      certificates: Certificates
    hostname: Hostname
    path:
      label: Path
      placeholder: e.g. /foo
    port:
      label: Port
      placeholder: e.g. 80 or http
    removePath: Remove
    requestHost:
      label: Request Host
      placeholder: e.g. example.com
    target:
      label: Target Service
      tooltip: If none of the Services in this dropdown select the Pods that ye need to expose, ye will need to create a Service that selects those Pods first.
      doesntExist: The selected service does not exist
    title: Rules
  rulesAndCertificates:
    title: Rules and Certificates
    defaultCertificate: default
  target:
    default: Default
  rulesOrBackendSpecified: Either Default Backend or Rules must be specified

internalExternalIP:
  none: None

istio:
  links:
    kiali:
      label: Kiali
      description: >
        Visualization o' services within a service mesh and how they be connected. Fer Kiali to display data, ye need Prometheus installed. If ye need a monitorin' solution, install <a tabindex="0" href="{link}">{vendor} monitorin'</a>.
    jaeger:
      label: Jaeger
      description: Monitor an' Troubleshoot microservices-based distributed systems.
    disabled: >
      {app} be not installed
  cni: Enable CNI
  customOverlayFile:
    label: Custom Overlay File
    tip: >
      The <a target="_blank" rel="noopener noreferrer nofollow" href="https://istio.io/latest/docs/setup/additional-setup/customize-installation/#patching-the-output-manifest">overlay file</a> allows fer additional configuration on top o' the base {vendor} Istio installation. Ye can utilize the <a href="https://istio.io/latest/docs/reference/config/istio.operator.v1alpha1/" target="_blank" rel="noopener noreferrer nofollow" >IstioOperator API</a> to make changes an' additions fer all components an' apply those changes via this overlay YAML file.
  description: >
    {vendor} Istio helm chart installs a minimal Istio configuration fer ye to get started integratin' wit' yer applications. If ye would like to get additional information about Istio, visit <a target="_blank" href="https://istio.io/latest/docs/concepts/what-is-istio" rel="noopener noreferrer nofollow">https://istio.io/latest/docs/concepts/what-is-istio/</a>
  destinationRule:
    title:
      new: Add Destination Rule
      edit: Edit Destination Rule
      view: "Destination Rule: {name}"
    port:
      label: Port
      placeholder: e.g. 8080 or myport
    host:
      label: Input a host
      error: Host be required.
    name:
      placeholder: e.g. myrule
    loadBalancer:
      title: Load Balancer
      label: Algorithm
      detail: Configure the load balancer algorithms
      simple:
        label: Use standard load balancin' algorithms
        roundRobin:
          label: Round Robin Policy
        leastConn:
          label: Least Request Load Balancer
        random:
          label: Random Load Balancer
        passthrough:
          label: Passthrough
      consistentHash:
        label: Use consistent hash-based load balancin' fer soft session affinity
        httpHeaderName:
          label: HTTP Header Name
          placeholder: e.g. end-user
          error: HTTP Header Name be required.
        minimumRingSize:
          label: Minimum Ring Size
          placeholder: e.g. 1024
        httpCookie:
          name:
            label: Cookie Name
            placeholder: e.g. username
            error: Cookie Name be required.
          path:
            label: Cookie Path
            placeholder: e.g. /
          ttl:
            label: TTL
            placeholder: e.g. 0s
            error: TTL be required.
        mode:
          label: Hash Mode
          header:
            label: Hash based on a specific HTTP header
          cookie:
            label: Hash based on HTTP cookie
          sourceIp:
            label: Hash based on the source IP address
    connectionPool:
      label: Connection Pool
      detail: Configure the volume o' connections to an upstream service
      http1MaxPendingRequests:
        label: HTTP1 Max Pending Requests
        placeholder: e.g. 1024
        help: Maximum number o' pending HTTP requests to a destination.
      http2MaxRequests:
        label: HTTP2 Max Requests
        placeholder: e.g. 1024
        help: Maximum number o' requests to a backend.
      maxRequestsPerConnection:
        label: HTTP Max Requests Per Connection
        placeholder: e.g. 10
        help: Maximum number o' requests per connection to a backend. Settin' this parameter to 1 disables keep alive.
      maxRetries:
        label: HTTP Max Retries
        placeholder: e.g. 1024
        help: Maximum number o' retries that can be outstanding to all hosts in a cluster at a given time.
      connectTimeout:
        label: TCP Connection Timeout
        placeholder: e.g. 30ms
        help: TCP connection timeout.
      maxConnections:
        label: TCP Max Connections
        placeholder: e.g. 1024
        help: Maximum number o' HTTP1 /TCP connections to a destination host.
    outlierDetection:
      label: Outlier Detection
      detail: Configure eviction o' unhealthy hosts from the load balancin' pool
      baseEjectionTime:
        label: Base Ejection Time
        placeholder: e.g. 30s
        help: Minimum ejection duration. A host will remain ejected fer a period equal to the product o' minimum ejection duration an' the number o' times the host has been ejected.
      consecutiveErrors:
        label: Consecutive Errors
        placeholder: e.g. 5
        help: Number o' errors before a host be ejected from the connection pool.
      interval:
        label: Interval
        placeholder: e.g. 10s
        help: Time interval between ejection sweep analysis.
      maxEjectionPercent:
        label: Max Ejection Percent
        placeholder: e.g. 10
        help: Maximum % o' hosts in the load balancin' pool fer the upstream service that can be ejected.
    subsets:
      label: Subsets
      noSubsets: No Subsets
      addSubsetLabel: Add Subset
      removeSubsetLabel: Remove Subset
      name:
        label: Name
        placeholder: e.g. v1
        error: Subset Name be required.
      labels:
        error: Please input at least one label fer subset.
    tls:
      label: TLS
      detail: Configure TLS related settings fer connections to the upstream service
      mode:
        label: TLS Mode
        none:
          label: NONE
        istio:
          label: Istio Mutual - Secure connections to the upstream usin' mutual TLS by Istio
        disable:
          label: Disable - Do not setup a TLS connection to the upstream endpoint
        simple:
          label: Simple - Originate a TLS connection to the upstream endpoint
        mutual:
          label: Mutual - Secure connections to the upstream usin' mutual TLS by presentin' client certificates fer authentication
      clientCertificate:
        label: Client Certificate
        placeholder: e.g. /etc/certs/myclientcert.pem
        error: Client Certificate be required.
      privateKey:
        label: Private Key
        placeholder: e.g. /etc/certs/client_private_key.pem
        error: Private Key be required.
      caCertificates:
        label: CA Certificates
        placeholder: e.g. /etc/certs/rootcacerts.pem
      sni:
        label: SNI
        placeholder: e.g. nginx.example.com
      subjectAltNames:
        label: Subject Alternative Names
        placeholder: e.g. example.com
        add: Add Subject Alternative Name
  egressGateway: Enable Egress Gateway
  ingressGateway: Enable Ingress Gateway
  istiodRemote: Enable istiodRemote
  kiali: Enable Kiali
  pilot: Enable Pilot
  policy: Enable Policy
  pilotRequired: Pilot must be enabled in order to enable Kiali
  poweredBy: Powered by <a target="_blank" rel="noopener noreferrer nofollow" href='https://istio.io/latest/'>Istio</a>
  telemetry: Enable Telemetry
  titles:
    components: Components
    customAnswers: Custom Answers
    advanced: Advanced Settin's
    description: Description
  tracing: Enable Jaeger Tracin' (limited)
  v1Warning: Please uninstall the current Istio version in the <code>istio-system</code> namespace before attemptin' to install this version.

labels:
  addLabel: Add Label
  addSetLabel: Add/Set Label
  addTag: Add Tag
  addTaint: Add Taint
  addAnnotation: Add Annotation
  labels:
    title: Labels
    description: Key/value pairs that be attached to objects which specify identifyin' attributes.
    fleetClusterTooltip: Label changes be made to the Management Cluster an' synchronized to the Fleet Cluster
    show: Show System Label
    hide: Hide System Label
  annotations:
    title: Annotations

landing:
  clusters:
    title: Clusters
    provider: Provider
    kubernetesVersion: Kubernetes Version
    explorer: Explorer
    explore: Explore
    cores: |-
      {count, plural,
      =1 {core}
      other {cores}}
    cpuUsed: CPU Used
    memoryUsed: Memory Used
  seeWhatsNew: Learn more about the improvements an' new capabilities in this version.
  whatsNewLink: "What's new in 2.7"
  learnMore: Learn More
  support: Support
  psps: PSPs
  deprecatedPsp: Pod Security Policies be deprecated as o' Kubernetes v1.21, an' have been removed in Kubernetes v1.25. Ye have one or more PodSecurityPolicy resource(s) in this cluster.
  community:
    title: Community Support
    docs: Docs
    forums: Forums
  commercial:
    title: Commercial Support
    body: Learn about commercial support
  landingPrefs:
    title: Ye can change what ye see when ye login via preferences
    userPrefs: Preferences
    body: "Ye can change where ye land when ye login"
    options:
      homePage: Take me to the home page
      lastVisited: Take me to the area I last visited
      custom: "Take me to cluster:"
  welcomeToRancher: >
    Welcome to {vendor}

logging:
  clusterFlow:
    noOutputsBanner: There be no cluster outputs in the selected namespace.
  flow:
    clusterOutputs:
      doesntExistTooltip: This cluster output doesn't exist
      label: Cluster Outputs
    matches:
      banner: Configure which container logs will be pulled from
      unsupportedConfig: This resource contains a match configuration that the form editor does not support. Please use YAML edit.
      label: Matches
      addSelect: Add Include Rule
      addExclude: Add Exclude Rule
      pods:
        title:
          include: Include Pods
          exclude: Exclude Pods
        keyLabel: Pod Label Key
        valueLabel: Pod Label Value
        addLabel: Add Pod
      nodes:
        title:
          include: Limit to specific nodes
          exclude: Exclude specific nodes
        placeholder: "Default: Any node"
      containerNames:
        title:
          include: Limit to specific container names
          exclude: Exclude specific container names
        placeholder: "Default: Any container"
      namespaces:
        title:
          include: Limit to specific namespaces
          exclude: Exclude specific namespaces
        placeholder: "Default: Any namespace"

    filters:
      label: Filters
    outputs:
      doesntExistTooltip: This output doesn't exist
      sameNamespaceError: Output must reside in same namespace as the flow.
      label: Outputs
  install:
    k3sContainerEngine: K3S Container Engine
    enableAdditionalLoggingSources: Enable enhanced cloud provider loggin'
    dockerRootDirectory: Docker Root Directory
    systemdLogPath: systemd Log Path
    tooltip: >
      Some kubernetes distributions log to <code>journald</code>. In order to collect these logs the <code>systemdLogPath</code> needs to be defined. While the <code>/run/log/journal</code> directory be used by default, some Linux distributions do not default to this path.
    url: >
      <a href="https://rancher.com/docs/rancher/v2.6/en/logging/helm-chart-options/" target="_blank" rel="noopener nofollow noreferrer">Learn more</a>
    default: /run/log/journal
  elasticsearch:
    host: Host
    scheme: Scheme
    port: Port
    indexName: Index Name
    user: User
    password: Password from Secret
    caFile:
      label: CA File from Secret
    clientCert:
      label: Client Cert from Secret
      placeholder: Paste in the CA certificate
    clientKey:
      label: Client Key from Secret
      placeholder: Paste in the client key
    clientKeyPass: Client Key Pass from Secret
    verifySsl: Verify SSL
    sslVersion: SSL Version
    suppressTypeName:
      label: Suppress Type Names
      elasticSearchTips: Suppress type names by default to be compatible with log server. Ye should enable it for Elasticsearch >= 8.0.0
      openSearchTips: Suppress type names by default to be compatible with log server. Ye should enable it for OpenSearch >= 2.0.0
  redis:
    host: Host
    port: Port
    dbNumber: Redis database number
    ttl: TTL fer each key
    password: Password from Secret
    format:
      title: Format
      type: Type
  gelf:
    host: Host
    port: Port
    protocol: Protocol
    tls: Enable TLS
    tlsOptions:
      clientCert: Client Cert
      clientKey: Client Cert Key
      allCiphers: Allow any ciphers to be used
      tlsVersion: TLS version
      noVerify: Skip TLS verification
  kafka:
    brokers: Brokers
    defaultTopic: Default Topic
    saslOverSsl: SASL Over SSL
    scramMechanism: Scram Mechanism
    username: Username from Secret
    password: Password from Secret
    sslCaCert:
      label: CA Cert from Secret
      placeholder: Paste in the CA certificate
    sslClientCert:
      label: Cert from Secret
      placeholder: Paste in the client cert
    sslClientCertChain:
      label: Cert Chain from Secret
      placeholder: Paste in the client cert chain
    sslClientCertKey: Cert Key from Secret
  loki:
    url: URL
    urlInvalid: Incorrect URL format. Please  check an' correct yer URL format before savin'.
    tenant: Tenant
    username: User from Secret
    password: Password from Secret
    configureKubernetesLabels: Configure Kubernetes metadata in a Prometheus like format
    extractKubernetesLabels: Extract Kubernetes labels as Loki labels
    dropSingleKey: If a record only has 1 key, then just set the log line to the value an' discard the key
    caCert: CA Cert from Secret
    cert: Cert from Secret
    key: Key from Secret
  awsElasticsearch:
    url: URL
    keyId: Key Id from Secret
    secretKey: Secret Key from Secret
  azurestorage:
    storageAccount: Account from Secret
    accessKey: Access Key from Secret
    container: Container
    path: Path
    storeAs: Store As
  cloudwatch:
    keyId: Key Id from Secret
    secretKey: Secret Key from Secret
    endpoint: Endpoint
    region: Region
    logGroupName: Log Group Name
    logStreamName: Log Stream Name
  datadog:
    apiKey: API Key from Secret
    useSSL: Use SSL
    useCompression: Use Compression
    host: Host
  file:
    path: Path
  gcs:
    project: Project
    credentialsJson: Credentials from Secret
    bucket: Bucket
    path: Path
    overwriteExistingPath: Overwrite Existin' Path
  kinesisStream:
    streamName: Stream Name
    keyId: Key Id from Secret
    secretKey: Secret Key from Secret
  logdna:
    apiKey: API Key
    hostname: Hostname
    app: App
  logz:
    url: URL
    port: Port
    token: Api Token from Secret
    enableCompression: Enable Compression
  newrelic:
    apiKey: API Key from Secret
    licenseKey: License Key from Secret
    baseURI: Base URI
  sumologic:
    endpoint: Endpoint from Secret
    sourceName: Source Name
  syslog:
    host: Host
    port: Port
    transport: Transport
    insecure: insecure
    trustedCaPath: CA Path from Secret
    format:
      title: Format
      type: Type
      addNewLine: Add New Line
      messageKey: Message Key
    buffer:
      title: Buffer
      tags: Tags
      chunkLimitSize: Chunk Limit Size
      chunkLimitRecords: Chunk Limit chunkLimitRecords
      totalLimitSize: Total Limit Size
      flushInterval: Flush Interval
      timekey: Timekey
      timekeyWait: Timekey Wait
      timekeyUseUTC: Timekey Use UTC
  s3:
    keyId: Key Id from Secret
    secretKey: Secret Key from Secret
    endpoint: Endpoint
    bucket: Bucket
    path: Path
    overwriteExistingPath: Overwrite Existin' Path
  output:
    buffer:
      label: Output Buffer
    selectOutputs: Select Outputs
    selectBanner: Select to configure an output
    sections:
      target: Target
      access: Access
      certificate: Connection
      labels: Labels
      configuration: Configuration
  outputProviders:
    elasticsearch: Elasticsearch
    opensearch: OpenSearch
    redis: Redis
    splunkHec: Splunk
    kafka: Kafka
    forward: Fluentd
    gelf: GELF
    loki: Loki
    awsElasticsearch: Amazon Elasticsearch
    azurestorage: Azure Storage
    cloudwatch: Cloudwatch
    datadog: Datadog
    file: File
    gcs: GCS
    kinesisStream: Kinesis Stream
    logdna: LogDNA
    logz: LogZ
    newrelic: New Relic
    sumologic: SumoLogic
    syslog: Syslog
    s3: S3
    unknown: Unknown
  overview:
    poweredBy: Banzai Cloud
    clusterLevel: Cluster-Level
    namespaceLevel: Namespace-Level
  provider: Provider
  splunk:
    host: Host
    port: Port
    protocol: Protocol
    index: Index
    token: Token from Secret
    insecureSsl: Insecure SSL
    indexName: Index Name
    source: Source
    caFile: CA File from Secret
    caPath: CA Path from Secret
    clientCert: Client Cert from Secret
    clientKey: Client Key from Secret
  forward:
    host: Host
    port: Port
    sharedKey: Shared Key from Secret
    username: Username from Secret
    password: Password from Secret
    clientCertPath: Client Cert Path from Secret
    clientPrivateKeyPath: Client Private Key Path from Secret
    clientPrivateKeyPassphrase: Client Private Key Passphrase from Secret

longhorn:
  overview:
    title: Overview
    subtitle: "Powered By: <a href='https://github.com/longhorn' target='_blank' rel='noopener nofollow noreferrer'>Longhorn</a>"
    linkedList:
      longhorn:
        label: >
          Longhorn
        description: >
          Manage storage system via UI
        na: Resource Unavailable

neuvector:
  overview:
    title: Overview
    subtitle: "Powered by: <a href='https://github.com/neuvector' target='_blank' rel='noopener nofollow noreferrer'>NeuVector</a>"
    linkedList:
      neuvector:
        label: >
          NeuVector
        description: >
          Full Lifecycle Container Security
        na: Resource Unavailable

login:
  howdy: Ahoy!
  welcome: Welcome to {vendor}
  loggedOut: Ye have been logged out.
  loginAgain: Log in again to continue.
  serverError:
    authFailedCreds: "Loggin' in failed: Check credentials, or yer account may not be authorized to log in."
    authFailed: "Loggin' in failed: Yer account may not be authorized to log in."
    unknown: "An unknown error occurred while attemptin' to login. Please contact yer system administrator."
    invalidSamlAttrs: "Invalid saml attributes"
    noResponse: "No response received"
  error: An error occurred loggin' in. Please try again.
  clientError: Invalid username or password. Please try again.
  useLocal: Use a local user
  loginWithProvider: Log in with {provider}
  username: Username
  password: Password
  loggingIn: Loggin' in...
  loggedIn: Logged in
  loginWithLocal: Log in with Local User
  useProvider: Use a {provider} user
  useNonLocal: Use a non-local user
  remember:
    label: Remember Username

managementNode:
  customName: Custom Name

members:
  clusterMembers: Cluster Members
  clusterAndProject: Cluster and Project Members
  project: Project Members
  createActionLabel: Add
  clusterMemebership: Cluster Membership
  projectMembership: Project Membership
  clusterPermissions:
    noDescription: User created - no description
    label: Cluster Permissions
    description: Controls what access users have to the Cluster
    createProjects: Create Projects
    manageClusterBackups: Manage Cluster Backups
    manageClusterCatalogs: Manage Cluster Catalogs
    manageClusterMembers: Manage Cluster Members
    manageNavlinks: Manage Navlinks
    manageNodes: Manage Nodes
    manageStorage: Manage Storage
    viewAllProjects: View All Projects
    viewClusterCatalogs: View Cluster Catalogs
    viewClusterMembers: View Cluster Members
    viewNodes: View Nodes
    owner:
      label: Owner
      description: Owners have full control over the Cluster and all resources inside it.
    member:
      label: Member
      description: Members can manage the resources inside the Cluster but not change the Cluster itself.
    custom:
      label: Custom
      description: Choose individual roles for this user.
      lockedRole: This role be locked.
  localClusterWarning: "Caution: This be the cluster that Rancher be usin' as a data store. Only administrators should be given write access to this cluster. Users with write access to this cluster can use it to grant themselves access to any part of this installation."
  noRolesAssigned: There be no users assigned to this project.

membershipEditor:
  label: Members
  user: User
  role: Role

monitoring:
  accessModes:
    many: ReadWriteMany
    once: ReadWriteOnce
    readOnlyMany: ReadOnlyMany
  aggregateDefaultRoles:
    label: Aggregate to Default Kubernetes Roles
    tip: >
      Adds labels to the ClusterRoles deployed by the Monitoring chart to <a target="_blank" rel="noopener nofollow noreferrer" href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/#aggregated-clusterroles"> aggregate to the corresponding default k8s admin, edit, and view ClusterRoles.</a>
  alerting:
    config:
      label: Alert Manager Config
    enable:
      label: Deploy Alertmanager
    secrets:
      additional:
        info: Secrets should be mounted at <pre class='inline-block m-0'>/etc/alertmanager/secrets/</pre>
        label: Additional Secrets
      existing: Choose an existing config secret
      info: |
        <span class="text-bold">Create default config</span>: A Secret containing yer Alertmanager Config will be created in the <pre class='inline-block m-0'>cattle-monitoring-system</pre> namespace on deployin' this chart under the name <pre class='inline-block m-0'>alertmanager-rancher-monitoring-alertmanager</pre>. By default, this Secret will never be modified on an uninstall or upgrade of this chart. <br />
        Once ye have deployed this chart, ye should edit the Secret via the UI in order to add yer custom notification configurations that will be used by Alertmanager to send alerts. <br /> <br />
        <span class="text-bold">Choose an existing config secret</span>: Ye must specify a Secret that exists in the <pre class='inline-block m-0'>cattle-monitoring-system</pre> namespace. If the namespace does not exist, ye will not be able to select an existing secret.
      label: Alertmanager Secret
      new: Create default config
      radio:
        label: Config Secret
    validation:
      duplicatedReceiverName: A receiver with the name {name} already exists.
    templates:
      keyLabel: File Name
      label: Template Files
      valueLabel: YAML Template
    title: Configure Alertmanager
  clusterType:
    label: Cluster Type
    placeholder: Select cluster type
  createDefaultRoles:
    label: Create Default Monitoring Cluster Roles
    tip: >
      Creates <code>monitoring-admin</code>, <code>monitoring-edit</code>, and <code>monitoring-view</code> ClusterRoles that can be assigned to users to provide permissions to CRDs installed by the Monitoring chart.
  etcdNodeDirectory:
    label: etcd Node Certificate Directory
    tooltip: >
      For clusters that use RancherOS for the etcd nodes, this option should be set to <pre class=''inline-block m-0''>/opt/rke/etc/kubernetes/ssl</pre>. Hybrid environments that require specifyin' multiple certificate directories (e.g. an etcd plane composed of both RancherOS and Ubuntu hosts) be not supported.
  grafana:
    storage:
      annotations: PVC Annotations
      className: Storage Class Name
      existingClaim: Use Existing Claim
      finalizers: PVC Finalizers
      label: Grafana Storage
      mode: Access Mode
      selector: Selector
      size: Size
      subpath: Use Subpath
      type: Persistent Storage Types
      types:
        existing: Enable With Existing PVC
        statefulset: Enable with StatefulSet Template
        template: Enable with PVC Template
      volumeName: Volume Name
    title: Configure Grafana
  hostNetwork:
    label: Use Host Network For Prometheus Operator
    tip: If ye be usin' a managed Kubernetes cluster with custom CNI (e.g. Calico), ye must enable this option to allow a managed control plane to contact the admission webhook exposed by Prometheus Operator to mutate or validate incoming PrometheusRules.
  overview:
    alertsList:
      ends:
        label: Ends At
      label: Active Alerts
      message:
        label: Message
      severity:
        label: Severity
      start:
        label: Starts At
    linkedList:
      alertManager:
        description: Active Alerts
        label: Alertmanager
      grafana:
        description: Metrics Dashboards
        label: Grafana
      na: Resource Unavailable
      prometheusPromQl:
        description: PromQL Graph
        label: Prometheus Graph
      prometheusRules:
        description: Configured Rules
        label: PrometheusRules
      prometheusTargets:
        description: Configured Targets
        label: Prometheus Targets
    subtitle: >
      Powered By: <a href="https://github.com/coreos/prometheus-operator" target="_blank" rel="noopener noreferrer nofollow">Prometheus</a>
    title: Dashboard
  prometheus:
    config:
      adminApi: Admin API
      evaluation: Evaluation Interval
      ignoreNamespaceSelectors:
        help: >
          Ignorin' Namespace Selectors allows Cluster Admins to limit teams from monitorin' resources outside of namespaces they have permissions to but can break the functionality of Apps that rely on settin' up Monitors that scrape targets across multiple namespaces, such as Istio.
        label: Namespace Selectors
        radio:
          enforced: >
            Use: Monitors can access resources based on namespaces that match the namespace selector field
          ignored: >
            Ignore: Monitors can only access resources in the namespace they be deployed in
      limits:
        cpu: CPU Limit
        memory: Memory Limit
      requests:
        cpu: Requested CPU
        memory: Requested Memory
      resourceLimits: Resource Limits
      retention: Retention
      retentionSize: Retention Size
      scrape: Scrape Interval
    storage:
      className: Storage Class Name
      label: Persistent Storage for Prometheus
      mode: Access Mode
      selector: Selector
      selectorWarning: >
        If ye be usin' a dynamic provisioner (e.g. Longhorn), no Selectors should be specified since a PVC with a non-empty selector can't have a PV dynamically provisioned for it.
      size: Size
      volumeName: Volume Name
    title: Configure Prometheus
    warningInstalled: |
      Warning: Prometheus Operators be currently deployed. Deployin' multiple Prometheus Operators onto one cluster be not currently supported. Please remove all other Prometheus Operator deployments from this cluster before tryin' to install this chart.
      If ye be migratin' from an older version of {vendor} with Monitoring enabled, please disable Monitoring on this cluster completely before attemptin' to install this chart.
  receiver:
    addReceiver: Add Receiver
    fields:
      name: Name
    tls:
      label: SSL
      caFilePath:
        label: CA File Path
        placeholder: e.g. ./ca-file.csr
      certFilePath:
        label: Cert File Path
        placeholder: e.g. ./cert-file.crt
      keyFilePath:
        label: Key File Path
        placeholder: e.g. ./key-file.pfx
      secretsBanner: The file paths below must be referenced in <pre class="inline-block m-0 p-0 vertical-middle">alertmanager.alertmanagerSpec.secrets</pre> when deployin' the Monitoring chart. For more information see our <a href="{docsBase}/monitoring-alerting/" target="_blank" rel="noopener noreferrer nofollow">documentation</a>.
  projectMonitoring:
    detail:
      error: "Unable to fetch Dashboard values with status: "
    list:
      banner: Project Monitoring Configuration be stored in ProjectHelmChart resources
      empty:
        message: Project Monitoring has not been configured for any projects
        canCreate: Get started by clickin' Create to add monitorin' to a project
        cannotCreate: Contact the admin to add project monitorin'
  route:
    label: Route
    fields:
      groupBy: Group By
      groupInterval: Group Interval
      groupWait: Group Wait
      receiver: Receiver
      repeatInterval: Repeat Interval
  routesAndReceivers: Routes and Receivers (Deprecated)
  monitors: Monitors
  projectMonitors: Project Monitoring
  alertmanagerConfig:
    description: Routes and receivers for project alertin' and cluster alertin' be configured within AlertmanagerConfig resources.
    empty: Alerts have not been configured for any accessible namespaces.
    getStarted: Get started by clickin' Create to configure an alert.
    receiverTooltip: This route will direct alerts to the selected receiver, which must be defined in the same AlertmanagerConfig.
    deprecationWarning: The Route and Receiver resources be deprecated. Goin' forward, routes and receivers should not be managed as separate Kubernetes resources on this page. They should be configured as YAML fields in an AlertmanagerConfig resource.
    routeInfo: This form supports configurin' one route that directs traffic to a receiver. Alerts can be directed to more receiver(s) by configurin' child routes in YAML.
    receiverFormNames:
      create: Create Receiver in AlertmanagerConfig
      edit: Edit Receiver in AlertmanagerConfig
      editYaml: Edit AlertmanagerConfig
      detail: Receiver in AlertmanagerConfig
    disabledReceiverButton: The receiver form be available after the AlertmanagerConfig be created
    error: An error occurred savin' the AlertmanagerConfig
    email:
      username: Auth Username
      password: Secret with Auth Password
    slack:
      apiUrl: Secret with Slack Webhook URL
    pagerDuty:
      routingKey: Secret with Routing Key
      serviceKey: Secret with Service Key
    opsgenie:
      apiKey: Secret with API Key
    webhook:
      url: URL
      urlSecret: URL Secret
      urlSecretTooltip: >
        urlSecret takes precedence over url. One of urlSecret and url should be defined.
    auth:
      bearerTokenSecret: Bearer Token Secret
      basicAuthUsername: Secret with Basic Auth Username
      basicAuthPassword: Secret with Basic Auth Password
  installSteps:
    uninstallV1:
      stepTitle: Uninstall V1
      stepSubtext: Uninstall Previous Monitorin'
      warning1: V1 Monitorin' be currently deployed. This needs to be uninstalled before V2 monitorin' can be installed.
      warning2: <a target="blank" href="{docsBase}/monitoring-alerting/guides/migrating/" target='_blank' rel='noopener nofollow'>Learn more</a> about the migration steps to V2 Monitorin'.
      promptDescription: <div class="mt-20 mb-20">Ye be attemptin' to uninstall V1 Monitorin'. Please ensure ye have read the migration steps.</div>
      success1: V1 monitorin' successfully uninstalled.
      success2: Press Next to continue
  tabs:
    alertin': Alertin'
    general: General
    grafana: Grafana
    prometheus: Prometheus
    projectMetrics: Project Metrics
  v1Warning: >
    Monitorin' be currently deployed from Cluster Manager. If ye be migratin' from an older version of {vendor} with monitorin' enabled, please disable monitorin' in Cluster Manager before attemptin' to install the new {vendor} Monitorin' chart in Cluster Explorer.

monitoringReceiver:
  addButton: Add {type}
  custom:
    label: Custom
    title: Custom Config
    info: The YAML provided here will be directly appended to yer receiver within the Alertmanager Config Secret.
  email:
    label: Email
    title: Email Config
  opsgenie:
    label: Opsgenie
    title: Opsgenie Config
  pagerduty:
    label: PagerDuty
    title: PagerDuty Config
    info: "Ye can find additional info on creatin' an Integration Key for PagerDuty <a href='https://www.pagerduty.com/docs/guides/prometheus-integration-guide/' target='_blank' rel='noopener nofollow' class='flex-right'>here</a>."
  slack:
    label: Slack
    title: Slack Config
    info: "Ye can find additional info on creatin' Incoming Webhooks for Slack <a href='https://rancher.slack.com/apps/A0F7XDUAZ-incoming-webhooks' target='_blank' rel='noopener noreferrer nofollow'>here</a> ."
  webhook:
    label: Webhook
    title: Webhook Config
    urlTooltip: For some webhooks this a url that points to the service DNS
    modifyNamespace: If <pre class="inline-block m-0 p-0 vertical-middle">rancher-alerting-drivers</pre> default values were changed, please update the url below in the format http://&lt;new_service_name&gt;.&lt;new_namespace&gt.svc.&lt;port&gt/&lt;path&gt
    banner: To use MS Teams or SMS ye will need to have at least one instance of <pre class="inline-block m-0 p-0 vertical-middle">rancher-alerting-drivers</pre> installed first.
    add:
      selectWebhookType: Select Webhook Type
      generic: Generic
      msTeams: MS Teams
      alibabaCloudSms: SMS
  auth:
    label: Auth
    authType: Auth Type
    username: Username
    password: Password
    none:
      label: None
    bearerToken:
      label: Bearer Token
      placeholder: e.g. secret-token
    basicAuth:
      label: Basic Auth
    bearerTokenFile:
      label: Bearer Token File
      placeholder: e.g. ./user_token
  tls:
    ca: Secret with CA
    cert: Secret with Client Cert
    key: Secret with Client Key
    serverName: Server Name
    serverNameTooltip: Used to verify the hostname for the targets.
  shared:
    proxyUrl:
      label: Proxy URL
      placeholder: e.g. http://my-proxy/
    sendResolved:
      label: Enable send resolved alerts

alertmanagerConfigReceiver:
  secretKeyId: Key Id from Secret
  name: Receiver Name
  addButton: Add Receiver
  receivers: Receivers
  namespaceWarning: Could not render the secret selector because no namespace was found to get secrets from.
  receiverTypes: "The followin' receiver types can be edited in forms: Email, Slack, PagerDuty, Opsgenie and Webhook. For other receiver types, edit the AlertmanagerConfig YAML."
  slack:
    webhookUrl: Webhook URL
    apiUrlTooltip: The secret's key that contains the Slack webhook URL. The secret needs to be in the same namespace as the AlertmanagerConfig object and accessible by the Prometheus Operator.
monitoringRoute:
  groups:
    label: Group By
    addGroupByLabel: Labels to Group Alerts By
    groupByTooltip: Add each label as a string in the format key:value. The special label ... will aggregate by all possible labels. If provided, the ... must be the only element in the list.
  info: This be the top-level Route used by Alertmanager as the default destination for any Alerts that do not match any other Routes. This Route must exist and cannot be deleted.
  interval:
    label: Group Interval
  matching:
    info: The root route has to match everythin' so matching cannot be configured.
    label: Match
    addMatcher: Add Matcher
    matchType: Match Type
    name: Name
    nameTooltip: Label to match
    value: Value
    valueTooltip: Label value to match
  receiver:
    type: Receiver Type
    add: Add Receiver
    label: Receiver
    oneOrMoreLabel: One or More Receivers
    addMatch: Add match
  regex:
    label: Match Regex
  repeatInterval:
    label: Repeat Interval
  wait:
    label: Group Wait

moveModal:
  title: Move to a new project?
  description: >
    Ye be movin' the followin' namespaces:
  moveButtonLabel: Move
  targetProject: Target Project

nameNsDescription:
  name:
    label: Name
    placeholder: >
      A unique name
  namespace:
    label: Sea
    placeholder: ""
  workspace:
    label: Workspace
    placeholder:
  description:
    label: Description
    placeholder: Any text ye want that better describes this resource

namespace:
  containerResourceLimit: Container Resource Limit
  resourceQuotas: Resource Quotas
  project:
    label: Project
    none: (None)
  resources: Resources
  enableAutoInjection: Enable Istio Auto Injection
  disableAutoInjection: Disable Istio Auto Injection
  move: Move
  total: Total
  workloads: Workloads
  label: Sea
  selectNamespace: Select Sea
  createNamespace: Create a New Sea
  selectOrCreate: Select or Create a Sea
  resourceStates:
    success: >
      Active
    info: >
      Transitionin'
    warning: >
      Warnin'
    error: >
      Error
    unknown: >
      Unknown
    paused:
      stateName: >
        Inactive
      shortDescription: Deployment be paused
      longDescription: Deployment be paused. Pausing stops the controller from deployin' revisions.

namespaceFilter:
  noMatchingOptions: No matchin' options
  more: "+{more}"
  selected:
    label: |-
      {total, plural,
      one {1 item selected}
      other {{total} items selected}
      }

namespaceList:
  selectLabel: Sea
  addLabel: Add Sea

navLink:
  name:
    label: Name
    placeholder: >
      e.g. foo-bar
  label:
    label: Display name
    placeholder: >
      Text displayed for the link
  tabs:
    link:
      label: Link type
      type:
        label: Link type
        service: Link to service
        url: Link to URL
      toURL:
        label: Destination URL
        placeholder: >
          e.g. https://rancher.com
      toService:
        service:
          label: Service (namespace/name)
          placeholder: >
            e.g. cattle-system/rancher-webhook
        path:
          label: Path
          placeholder: >
            e.g. proxy/?orgId=1
        port:
          label: Port
          placeholder: >
            e.g. 80
        scheme:
          label: Scheme
          placeholder: >
            e.g. http
    target:
      label: Window target
      option:
        blank: New window
        self: Replace window
        named: Custom named window
      namedValue:
        label: Window name
    group:
      label: Group
      group:
        label: Group name
        tooltip: Assign link to a group
      sideLabel:
        label: Link Label
      description:
        label: Link description
      iconSrc:
        label: Add image
networkpolicy:
  egress:
    label: Egress Rules
    enable: Configure egress rules to restrict outgoing traffic
    ruleLabel: Targets
    ruleHint: Outgoin' traffic be only allowed to the configured targets
    portHint: Outgoin' traffic be only allowed to connect to the configured ports
  ingress:
    label: Ingress Rules
    enable: Configure ingress rules to restrict incomin' traffic
    ruleLabel: Sources
    ruleHint: Incomin' traffic be only allowed from the configured sources
    portHint: Incomin' traffic be only allowed to connect to the configured ports
  labelsAnnotations:
    label: Labels & Annotations
  rules:
    pod: Pod
    namespace: Sea
    ruleLabel: Rule {index}
    addPort: Add allowed port
    type: Rule type
    ingress:
      add: Add allowed traffic source
    egress:
      add: Add allowed traffic target
    ports:
      label: Allowed ports
      port:
        label: Port
        placeholder: e.g. 8080
      protocol: Protocol
    ipBlock:
      label: IP block
      exceptions: Exceptions
      cidr:
        label: CIDR
        placeholder: e.g. 1.1.1.0/24
      addExcept: Add exception
      invalidCidr: "Invalid CIDR"
      invalidExceptionCidrs: "Invalid Exceptions: "
    podSelector:
      label: Pod Selector
    namespaceSelector:
      label: Sea Selector
    namespaceAndPodSelector:
      label: Sea/Pod Selector
  config:
    label: Configuration
  selectors:
    label: Selectors
    hint: The NetworkPolicy be applied to the selected Pods
    matchingPods:
      matchesSome: |-
        {matched, plural,
          =0 {Matches 0 of {total, number} pods}
          =1 {Matches 1 of {total, number} pods: "{sample}"}
          other {Matches {matched, number} of {total, number} existin' pods, includin' "{sample}"}
        }
    matchingNamespaces:
      matchesSome: |-
        {matched, plural,
          =0 {Matches 0 of {total, number} seas}
          =1 {Matches 1 of {total, number} seas: "{sample}"}
          other {Matches {matched, number} of {total, number} existin' seas, includin' "{sample}"}
        }
    matchingNamespacesAndPods:
      tooltip: A single entry rule that specifies both Sea Selector and Pod Selector that selects particular Pods within particular seas
      matchesSome: |-
        {matchedPods, plural,
          =0 {Matches 0 of {totalPods, number} pods}
          =1 {Matches 1 of {totalPods, number} pods: "{samplePods}"}
          other {Matches {matchedPods, number} of {totalPods, number} existin' pods, includin' "{samplePods}"}
        } in {matchedNamespaces, plural,
          =0 {0 of {totalNamespaces, number} seas}
          =1 {1 of {totalNamespaces, number} seas: "{sampleNamespaces}"}
          other {{matchedNamespaces, number} of {totalNamespaces, number} existin' seas, includin' "{sampleNamespaces}"}
        }
node:
  list:
    pool: Pool
    noNodes: This pool be empty
    nodeTaint: Taints
    scaleDown: Scale Pool Down
    scaleUp: Scale Pool Up
    poolDescription:
      noSize: No Size
      noLocation: No Location
    nodeLabels: Labels
    hideLabels: Show less
    showLabels: Show more
  detail:
    detailTop:
      containerRuntime: Container Runtime
      internalIP: Internal IP
      externalIP: External IP
      os: OS
      version: Version
    glance:
      consumptionGauge:
        used: Used
        amount: "{used} of {total} {unit}"
        cpu: CPU
        memory: MEMORY
        pods: PODS
      diskPressure: Disk Pressure
      kubelet: kubelet
      memoryPressure: Memory Pressure
      pidPressure: PID Pressure
    tab:
      conditions: Conditions
      images: Images
      metrics: Metrics
      info:
        label: Info
        key:
          architecture: Architecture
          bootID: Boot ID
          containerRuntimeVersion: Container Runtime Version
          kernelVersion: Kernel Version
          kubeProxyVersion: Kube Proxy Version
          kubeletVersion: Kubelet Version
          machineID: Machine ID
          operatingSystem: Operating System
          osImage: Image
          systemUUID: System UUID
      pods: Pods
      taints: Taints
  actions:
    downloadSSHKey: Loot SSH Key
    downloadNodeConfig: Loot Keys
    scaleDown: Scale Down
    forceDelete: Force Delete

persistentVolume:
  pluginConfiguration:
    label: Arrr Plugin configuration
  plugin:
    label: Volume Plugin
    inTree: in-tree plugin
    unsupported: (Unsupported)
  capacity:
    label: Capacity
  customize:
    label: Customize
    affinity:
      label: Ship Selectors
      addLabel: Add Ship Selector
    assignToStorageClass:
      label: Assign to Treasure Class
    mountOptions:
      label: Mount Options
      addLabel: Add Option
    accessModes:
      label: Access Modes
      readWriteOnce: Single Ship Read-Write
      readOnlyMany: Many Ships Read-Only
      readWriteMany: Many Ships Read-Write
  shared:
    partition:
      label: Partition
      placeholder: e.g. 1; 0 for entire device
    readOnly:
      label: Read Only
    filesystemType:
      label: Filesystem Type
      placeholder: e.g. ext4
    secretName:
      label: Secret Name
      placeholder: e.g. secret
    secretNamespace:
      label: Secret Sea
      placeholder: e.g. default
    monitors:
      add: Add Spyglass
  vsphereVolume:
    label: VMWare vSphere Volume
    volumePath:
      label: Volume Path
      placeholder: e.g. /
    storagePolicyName:
      label: Storage Policy Name
      placeholder: e.g. sp
    storagePolicyId:
      label: Storage Policy ID
      placeholder: e.g. sp1
  csi:
    label: CSI (Unsupported)
    suffix: (CSI)
    driver:
      label: Driver
      placeholder: e.g. driver.longhorn.io
    volumeHandle:
      label: Volume Handle
      placeholder: e.g. pvc-xxxx
    volumeAttributes:
      add: Add Volume Attribute
    nodePublishSecretName:
      label: Node Publish Secret Name
      placeholder: e.g. secret
    nodePublishSecretNamespace:
      label: Node Publish Secret Sea
      placeholder: e.g. default
    nodeStageSecretName:
      label: Node Stage Secret Name
      placeholder: e.g. secret
    nodeStageSecretNamespace:
      label: Node Stage Secret Sea
      placeholder: e.g. default
    controllerExpandSecretName:
      label: Controller Expand Secret Name
      placeholder: e.g. secret
    controllerExpandSecretNamespace:
      label: Controller Expand Secret Sea
      placeholder: e.g. default
    controllerPublishSecretName:
      label: Controller Publish Secret Name
      placeholder: e.g. secret
    controllerPublishSecretNamespace:
      label: Controller Publish Secret Sea
      placeholder: e.g. default
    drivers:
      disk-csi-azure-com: Azure Disk (CSI)
      file-csi-azure-com: Azure File (CSI)
      driver-longhorn-io: Longhorn (CSI)
      driver-harvesterhci-io: Harvester (CSI)
      nfs-csi-k8s-io: NFS (CSI)
      ebs-csi-aws-com: AWS Elastic Block Store (CSI)
      rbd-csi-ceph-com: Ceph RBD (CSI)
      org-gluster-glusterfs: GlusterFS (CSI)
      pd-csi-storage-gke-io: GCE Persistent Disk (CSI)
      cinder-csi-openstack-org: Cinder (CSI)
      pxd-portworx-com: Portworx (CSI)
      quobyte-csi: Quobyte (CSI)
      storageos: StorageOS (CSI)
      csi-vsphere-vmware-com: vSphere (CSI)
  cephfs:
    label: Ceph Filesystem (Unsupported)
    path:
      label: Path
      placeholder: e.g. /var
    user:
      label: Buccaneer
      placeholder: e.g. root
    secretFile:
      label: Secret File
      placeholder: e.g. secret
  rbd:
    label: Ceph RBD (Unsupported)
    user:
      label: Buccaneer
      placeholder: e.g. root
    keyRing:
      label: Key Ring
      placeholder: e.g. /etc/ceph/keyring
    pool:
      label: Pool
      placeholder: e.g. rbd
    image:
      label: Image
      placeholder: e.g. image
  fc:
    label: Fibre League (Unsupported)
    targetWWNS:
      add: Add Target WWN
    wwids:
      add: Add WWID
    lun:
      label: Lun
      placeholder: e.g. 2
  flexVolume:
    label: Flex Volume (Unsupported)
    driver:
      label: Driver
      placeholder: e.g. driver
    options:
      add: Add Option
  flocker:
    label: Flocker (Unsupported)
    datasetName:
      label: Dataset Name
      placeholder: e.g. dataset
    datasetUUID:
      label: Dataset UUID
      placeholder: e.g. uuid
  glusterfs:
    label: Gluster Volume (Unsupported)
    endpoints:
      label: Endpoints
      placeholder: e.g. glusterfs-cluster
    path:
      label: Path
      placeholder: e.g. kube-vol
  iscsi:
    label: iSCSI Target (Unsupported)
    initiatorName:
      label: Initiator Name
      placeholder: iqn.1994-05.com.redhat:1df7a24fcb92
    iscsiInterface:
      label: iSCSI Interface
      placeholder: e.g. interface
    chapAuthDiscovery:
      label: Chap Auth Discovery
    chapAuthSession:
      label: Chap Auth Session
    iqn:
      label: IQN
      placeholder: iqn.2001-04.com.example:storage.kube.sys1.xyz
    lun:
      label: Lun
      placeholder: e.g. 2
    targetPortal:
      label: Target Portal
      placeholder: e.g. portal
    portals:
      add: Add Portal
  cinder:
    label: Openstack Cinder Volume (Unsupported)
    volumeId:
      label: Volume ID
      placeholder: e.g. vol
  quobyte:
    label: Quobyte Volume (Unsupported)
    volume:
      label: Volume
      placeholder: e.g. vol
    user:
      label: Buccaneer
      placeholder: e.g. root
    group:
      label: Crew
      placeholder: e.g. abc
    registry:
      label: Registry
      placeholder: e.g. abc
  photonPersistentDisk:
    label: Photon Volume (Unsupported)
    pdId:
      label: PD ID
      placeholder: e.g. abc
  portworxVolume:
    label: Portworx Volume (Unsupported)
    volumeId:
      label: Volume ID
      placeholder: e.g. abc
  scaleIO:
    label: ScaleIO Volume (Unsupported)
    volumeName:
      label: Volume Name
      placeholder: e.g. vol-0
    gateway:
      label: Gateway
      placeholder: e.g. https://localhost:443/api
    protectionDomain:
      label: Protection Domain
      placeholder: e.g. pd01
    storageMode:
      label: Storage Mode
      placeholder: e.g. ThinProvisioned
    storagePool:
      label: Storage Pool
      placeholder: e.g. sp01
    system:
      label: System
      placeholder: e.g. scaleio
    sslEnabled:
      label: SSL Enabled
  storageos:
    label: StorageOS (Unsupported)
    volumeName:
      label: Volume Name
      placeholder: e.g. vol
    volumeNamespace:
      label: Volume Sea
      placeholder: e.g. default
  nfs:
    label: Plunder Share
    path:
      label: Path
      placeholder: e.g. /var
    server:
      label: Server
      placeholder: e.g. 10.244.1.4
  longhorn:
    label: Longhorn
    volumeHandle:
      label: Volume Handle
      placeholder: e.g. pvc-xxxx
    options:
      label: Options
      addLabel: Add
  local:
    label: Local
    path:
      label: Path
      placeholder: e.g. /mnt/disks/ssd1
  hostPath:
    label: HostPath
    pathOnTheNode:
      label: Path on the Ship
      placeholder: /mnt/disks/ssd1
    mustBe:
      label: The Path on the Ship must be
      anything: >
        Anything: do not check the target path
      directory: A hold, or create if it does not exist
      file: A parchment, or create if it does not exist
      existingDirectory: An existing hold
      existingFile: An existing parchment
      existingSocket: An existing spyglass
      existingCharacter: An existing compass
      existingBlock: An existing anchor
  gcePersistentDisk:
    label: Google Persistent Disk
    persistentDiskName:
      label: Persistent Disk Name
      placeholder: e.g. abc
  awsElasticBlockStore:
    label: Amazon EBS Disk
    volumeId:
      label: Volume ID
      placeholder: e.g. volume1
  azureFile:
    label: Azure Filesystem
    shareName:
      label: Share Name
      placeholder: e.g. abc
  azureDisk:
    label: Azure Disk
    diskName:
      label: Disk Name
      placeholder: e.g. kubernetes-pvc
    diskURI:
      label: Disk URI
      placeholder: e.g. https://example.com/disk
    kind:
      label: Kind
      dedicated: Dedicated
      managed: Managed
      shared: Shared
    cachingMode:
      label: Caching Mode
      none: None
      readOnly: Read Only
      readWrite: Read Write
    filesystemType:
      label: Filesystem Type
      placeholder: e.g. ext4
    readOnly:
      label: Read Only

persistentVolumeClaim:
  name: Plunder Volume Claim Name
  accessModes: Access Modes
  accessModesOptions:
    singleNodeRW: Single-Ship Read-Write
    manyNodeR: Many-Ships Read-Only
    manyNodeRW: Many-Ships Read-Write
  capacity: Capacity
  storageClass: Treasure Class
  useDefault: Use the default class
  volumes: Plunder Volumes
  volumeName: Plunder Volume Name
  source:
    label: Source
    options:
      new: Use a Treasure Class to provision a new Plunder Volume
      existing: Use an existing Plunder Volume
  expand:
    label: Expand
    notSupported: Treasure class does not support volume expansion
    notBound: Only bound Plunder Volume Claims can be expanded
  volumeClaim:
    label: Volume Claim
    storageClass: Treasure Class
    requestStorage: Request Storage
    persistentVolume: Plunder Volume
    tooltips:
      noStorageClass: Ye don't have permission to list Treasure Classes, enter a name manually
      noPersistentVolume: Ye don't have permission to list Plunder Volumes, enter a name manually
  customize:
    label: Customize
    accessModes:
      readWriteOnce: Single Ship Read-Write
      readOnlyMany: Many Ships Read-Only
      readWriteMany: Many Ships Read-Write
  status:
    label: Status

podDisruptionBudget:
  budget:
    label: Budget
  minAvailable:
    label: Min. available Ships
  maxUnavailable:
    label: Max. unavailable Ships

inactivity:
  title: Session expiring
  titleExpired: Session expired
  banner: Yer session be about to expire due to inactivity. Any unsaved changes will be lost.
  bannerExpired: Yer session has expired in this tab due to inactivity.
  content: Click "Resume Session" to keep the session in this tab active or refresh the browser after the session has expired.
  contentExpired: To return to this page click "Refresh" below or refresh the browser.
  cta: Resume Session
  ctaExpired: Refresh
